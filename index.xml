<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cheon&#39;s blog</title>
    <link>https://www.cheon.site/blog/</link>
    <description>Recent content on cheon&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Dec 2019 16:40:16 +0800</lastBuildDate>
    
	<atom:link href="https://www.cheon.site/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Proxy Settings</title>
      <link>https://www.cheon.site/blog/solved/proxy_settings/</link>
      <pubDate>Mon, 16 Dec 2019 16:40:16 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/proxy_settings/</guid>
      <description>Table of Contents  常见代理设置  git npm pip   常见代理设置 git git config --global http.proxy http://ip:port git config --global https.proxy http://ip:port 或者编辑 $HOME/.gitconfig:
[http] proxy = http://ip:port [https] proxy = http://ip:port 删除代理:
git config --global --unset http.proxy git config --global --unset https.proxy git 也支持 socks5 代理，把 http 替换为 socks5 即可。
npm 临时代理:
npm --registry=https://registry.npm.taobao.org install 全局配置:
npm config set registry https://registry.npm.taobao.org 或者编辑 $HOME/.npmrc:
registry=https://registry.npm.taobao.org 删除代理:
npm config delete registry pip 编辑 $HOME/.</description>
    </item>
    
    <item>
      <title>GNU Argp</title>
      <link>https://www.cheon.site/blog/c/gnu_argp/</link>
      <pubDate>Thu, 28 Nov 2019 15:21:52 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/c/gnu_argp/</guid>
      <description>Table of Contents  GNU Argp 库  前置知识  从一个示例开始 命令行参数 选项的参数  step0: 第一个 argp 程序 step1: 短选项 step2: 选项参数 step3: 长选项 step4: 可选项 step5: 别名 step6: 回调自身 step7: 参数支持 step8: 隐藏选项 step9: 完善说明 step10: 选项组 step11: 调用库   
GNU Argp 库 c 命令行程序中的参数处理是很常见的需求，要做到这点我们可以用 GNU 的标准库 argp，大部分 GNU 组件都用这个库来解析参数。

前置知识 
从一个示例开始 先来看一个例子:
  sum --help 
sum --help Usage: sum [OPTION]... [FILE]... Print checksum and block counts for each FILE.</description>
    </item>
    
    <item>
      <title>Archlinux Nvidia</title>
      <link>https://www.cheon.site/blog/system/archlinux_nvidia/</link>
      <pubDate>Sun, 29 Sep 2019 14:07:53 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/archlinux_nvidia/</guid>
      <description>Table of Contents  ArchLinux 配置 nvidia 独立显卡 firefox webgl 配置独立显卡  
ArchLinux 配置 nvidia 独立显卡 按照 PRIME Render Offload 文档，安装新版本的 nvidia 驱动和 xorg，新版本的 xorg 安装包可以从 arch-xorg-server 构建。 修改配置文件 /etc/X11/xorg.conf ，主要添加
Section &amp;#34;ServerLayout&amp;#34; Identifier &amp;#34;layout&amp;#34; Option &amp;#34;AllowNVIDIAGPUScreens&amp;#34; EndSection 完整配置如下:
 xorg.conf
Section &amp;#34;ServerLayout&amp;#34; Identifier &amp;#34;X.org Configured&amp;#34; Screen 0 &amp;#34;Screen0&amp;#34; 0 0 #Screen 1 &amp;#34;Screen1&amp;#34; RightOf &amp;#34;Screen0&amp;#34; InputDevice &amp;#34;Mouse0&amp;#34; &amp;#34;CorePointer&amp;#34; InputDevice &amp;#34;Keyboard0&amp;#34; &amp;#34;CoreKeyboard&amp;#34; Option &amp;#34;AllowNVIDIAGPUScreens&amp;#34; EndSection Section &amp;#34;Files&amp;#34; ModulePath &amp;#34;/usr/lib/xorg/modules&amp;#34; ModulePath &amp;#34;/usr/lib/modules/extramodules-ARCH&amp;#34; FontPath &amp;#34;/usr/share/fonts/TTF&amp;#34; FontPath &amp;#34;/usr/share/fonts/adobe-source-code-pro&amp;#34; EndSection Section &amp;#34;Module&amp;#34; Load &amp;#34;glx&amp;#34; Load &amp;#34;nvidia-drm&amp;#34; EndSection Section &amp;#34;InputDevice&amp;#34; Identifier &amp;#34;Keyboard0&amp;#34; Driver &amp;#34;kbd&amp;#34; EndSection Section &amp;#34;InputDevice&amp;#34; Identifier &amp;#34;Mouse0&amp;#34; Driver &amp;#34;mouse&amp;#34; Option	&amp;#34;Protocol&amp;#34; &amp;#34;auto&amp;#34; Option	&amp;#34;Device&amp;#34; &amp;#34;/dev/input/mice&amp;#34; Option	&amp;#34;ZAxisMapping&amp;#34; &amp;#34;4 5 6 7&amp;#34; EndSection Section &amp;#34;Monitor&amp;#34; Identifier &amp;#34;Monitor0&amp;#34; VendorName &amp;#34;Monitor Vendor&amp;#34; ModelName &amp;#34;Monitor Model&amp;#34; EndSection Section &amp;#34;Device&amp;#34; ### Available Driver options are:- ### Values: &amp;lt;i&amp;gt;: integer, &amp;lt;f&amp;gt;: float, &amp;lt;bool&amp;gt;: &amp;#34;True&amp;#34;/&amp;#34;False&amp;#34;, ### &amp;lt;string&amp;gt;: &amp;#34;String&amp;#34;, &amp;lt;freq&amp;gt;: &amp;#34;&amp;lt;f&amp;gt; Hz/kHz/MHz&amp;#34;, ### &amp;lt;percent&amp;gt;: &amp;#34;&amp;lt;f&amp;gt;%&amp;#34; ### [arg]: arg optional #Option &amp;#34;SWcursor&amp;#34; # [&amp;lt;bool&amp;gt;] #Option &amp;#34;kmsdev&amp;#34; # &amp;lt;str&amp;gt; #Option &amp;#34;ShadowFB&amp;#34; # [&amp;lt;bool&amp;gt;] #Option &amp;#34;AccelMethod&amp;#34; # &amp;lt;str&amp;gt; #Option &amp;#34;PageFlip&amp;#34; # [&amp;lt;bool&amp;gt;] #Option &amp;#34;ZaphodHeads&amp;#34; # &amp;lt;str&amp;gt; #Option &amp;#34;DoubleShadow&amp;#34; # [&amp;lt;bool&amp;gt;] Option &amp;#34;RenderAccel&amp;#34; &amp;#34;1&amp;#34; Option &amp;#34;DPMS&amp;#34; &amp;#34;1&amp;#34; Option &amp;#34;RegistryDwords&amp;#34; &amp;#34;EnableBrightnessControl=1&amp;#34; Identifier &amp;#34;Card0&amp;#34; Driver &amp;#34;modesetting&amp;#34; BusID &amp;#34;PCI:0:2:0&amp;#34; EndSection Section &amp;#34;Device&amp;#34; Identifier &amp;#34;Card1&amp;#34; Driver &amp;#34;nvidia&amp;#34; BusID &amp;#34;PCI:1:0:0&amp;#34; Option &amp;#34;RenderAccel&amp;#34; &amp;#34;1&amp;#34; Option &amp;#34;DPMS&amp;#34; &amp;#34;1&amp;#34; Option &amp;#34;RegistryDwords&amp;#34; &amp;#34;EnableBrightnessControl=1&amp;#34; Option &amp;#34;RegistryDwords&amp;#34; &amp;#34;PowerMizerLevelAC=0x3&amp;#34; Option &amp;#34;RegistryDwords&amp;#34; &amp;#34;PowerMizerLevel=0x2&amp;#34; Option &amp;#34;RegistryDwords&amp;#34; &amp;#34;PerfLevelSrc=0x3333&amp;#34; Option &amp;#34;OnDemandVBlankInterrupts&amp;#34; &amp;#34;1&amp;#34; EndSection Section &amp;#34;Screen&amp;#34; Identifier &amp;#34;Screen0&amp;#34; Device &amp;#34;Card0&amp;#34; Monitor &amp;#34;Monitor0&amp;#34; SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 1 EndSubSection SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 4 EndSubSection SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 8 EndSubSection SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 15 EndSubSection SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 16 EndSubSection SubSection &amp;#34;Display&amp;#34; Viewport 0 0 Depth 24 EndSubSection EndSection</description>
    </item>
    
    <item>
      <title>Low Level I/O</title>
      <link>https://www.cheon.site/blog/c/low_level_io/</link>
      <pubDate>Tue, 27 Aug 2019 09:07:47 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/c/low_level_io/</guid>
      <description>底层 I/O 任务由标准 I/O 库函数执行，即缓冲和输入/输出转换，不总是可取的。例如，直接和诸如磁带驱动器之类的设备执行输入和输出时，程序员需要能够确定缓冲区要使用的大小，而不是让 stdio 的函数执行它。当然，系统提供这一层级的控制。标准 I/O 库是底层 I/O 库的一个用户友好的接口。
文件描述符 在标准 I/O 中，文件由文件指针引用。使用底层接口时，文件由文件描述符引用，由一个简单的整数来指代。在标准 I/O 中，有三个预先定义的文件描述符，0,1,2，分别指向标准输入，标准输出和标准错误输出。
不同于标准 I/O 库，为标准输入输出提供了速记函数，所有的底层 I/O 函数需要一个合适的文件描述符传递给它们。
打开和创建文件 open 函数用于打开一个文件用于读写或创建。它接收三个参数：要打开文件名的字符串，一个整数指定文件的打开方式，一个整数 mode 当创建一个文件。成功时，它返回一个整数的文件描述符，失败时返回 -1。第二个参数在 sys/file.h(Berkeley) 或 sys/fcntl.h(System V)中定义如下：
 O_RDONLY 只读模式 O_WRONLY 只写模式 O_RDWR 读写模式 O_APPEND 追加模式 O_CREAT 创建文件如果不存在，这个模式应该给出第三个参数 O_TRUNC 截断文件长度为0用于写 O_EXCL 返回错误如果创建文件时文件存在 O_NDELAY 打开文件时不阻塞  关闭文件 close 函数用于关闭文件，只接收一个参数，引用于要关闭文件的文件描述符。成功时返回0；出错时返回-1。
读写文件 在底层接口中读写文件只有一个办法，一次一个缓冲区。缓冲区大小留给程序员定义，需要确定一个合适的值。例如，如果一个程序一侧值读写一个字符而不是几千个字符，操作系统将为每个字符都访问一次硬盘（或其他设备），导致程序执行非常缓慢。
read 系统调用接收三个参数：一个文件描述符用于读取，一个指针指向缓冲区等待填写数据，一个整数表示要读取的字节数。返回实际读取的字节数，或者出错时返回 -1，到达文件末尾时返回 0。
write 系统调用接收三个参数：一个文件描述符用于写入，一个指针指向缓冲区存放要写的数据，一个整数表示要写入的字节数。返回实际写入的字节数，或者出错时返回 -1。
下面的代码实现了文件追加的功能：
 code
#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;string.</description>
    </item>
    
    <item>
      <title>Standard I/O</title>
      <link>https://www.cheon.site/blog/c/standard_io/</link>
      <pubDate>Fri, 23 Aug 2019 09:29:15 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/c/standard_io/</guid>
      <description>c 常用标准输入输出 在 c 程序中，常使用标准 I/O 库(stdio)中的方法来实现输入输出操作。这些方法是高层次的输入输出，因为他们有三个重要的功能:
 缓冲区自动操作。相对于一次写入几个字节数据，这些方法实际上一次可以写入一大块数据，通常有数千个字节。缓冲区的大小在 stdio.h 的常量 BUFSIZ 定义。
 输入和输出的转换。例如当使用 printf 来打印一个整数(用 %d 控制)，代表那个整数的字符将会被打印。相似的，当使用 scanf，代表那个数字的字符被转换成数值。
 输入和输出自动格式化。你可以指定宽度以及其他任何格式来打印数字和字符串。
  文件指针 在标准 I/O 库中，一个文件被称为一个流(stream)，用一个指向 FILE 类型的对象指针来描述，叫做文件指针(file pointer)。FILE 文件类型在 stdio.h 中定义。有三个预先定义好的文件指针：stdin，stdout，stderr，分别代表标准输入（键盘），标准输出（终端屏幕），和标准错误输出。
大多数标准输入输出库中的函数需要一个文件指针代表一个打开的流作为参数。当从标准输入读取数据或输出到标准输出时，标准 I/O 库提供了一些速记函数来指定这些流而无需再传递参数。下表指明了这些速记函数和他们的等价函数:
   Shorthand Equivalent     getchar() fgetc(stdin), getc(stdin)   gets(buf) fgets(buf, BUFSIZ, stdin)   printf(args) fprintf(stdout, args)   putchar(c) fputc(c, stdout), putc(c, stdout)   puts(buf) fputs(buf, stdout)   scanf(args) fscanf(stdin, args)    打开和创建文件 为了能够从文件读或写入文件，那个文件必须被打开用于读写。fopen 函数就是用于这个目的。这个函数读取两个参数：一个字符串代表文件名，一个字符串用于描述文件被怎样打开。它返回一个打开的 FILE 文件流，或者如果无法打开指定文件时会返回常量 NULL。fopen 的第二个参数可以是以下值：</description>
    </item>
    
    <item>
      <title>K8s Note</title>
      <link>https://www.cheon.site/blog/struct/k8s_note/</link>
      <pubDate>Thu, 01 Aug 2019 16:34:31 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/k8s_note/</guid>
      <description>k8s 备忘 ingress 配置证书 首先要在 ingress 所在 namespace 下创建 tls 类型的 secret:
kubectl create secret tls https-certs --key /path/to/keyfile --cert /path/to/certfile -n the-namespace 修改 ingress 配置，kubectl edit ing ingname -n the-namespace，在 spec 添加如下内容，注意和 rules 同级:
tls: - hosts: - www.test.com secretName: https-certs ingress 配置了 https 证书后默认会强制跳转到 https 协议，如果不想强制跳转，可以在 annotations 添加如下配置:
nginx.ingress.kubernetes.io/ssl-redirect: &amp;#34;false&amp;#34; 旧版本的配置无需加上 nginx 前缀:
ingress.kubernetes.io/ssl-redirect: &amp;#34;false&amp;#34; 更多的 annotations 配置可以查看 github 文档
ingress 配置超时 应用接口响应较慢的情况下可能需要修改 nginx 的超时配置，默认是 60s，可以在 annotations 添加如下配置:</description>
    </item>
    
    <item>
      <title>Logstash to ES</title>
      <link>https://www.cheon.site/blog/struct/logstash_to_es/</link>
      <pubDate>Thu, 04 Jul 2019 09:26:33 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/logstash_to_es/</guid>
      <description>logstash 配置日志发送 ES 日志收集的架构如下所示:
┌────────────┐ │Java logback│\ └────────────┘ \ ┌─────┐ ┌────────┐ ┌──────┐ ┌────────┐ │kafka│ ───&amp;gt; │logstash│ ───&amp;gt; │ ES │ ───&amp;gt; │ kibana │ └─────┘ └────────┘ └──────┘ └────────┘ ┌────────────┐ / │Java logback│/ └────────────┘ java 应用日志通过 logback 发送给 kafka，logstash 从 kafka 消费日志，并将日志转发给 ES。一开始一个应用一个 kafka topic，logstash 消费了之后根据 topic 来确定 ES 的索引。
logback 的配置:
 logback.xml
&amp;lt;appender name=&amp;#34;KAFKA&amp;#34; class=&amp;#34;com.github.danielwegener.logback.kafka.KafkaAppender&amp;#34;&amp;gt; &amp;lt;encoder class=&amp;#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder&amp;#34; charset=&amp;#34;UTF-8&amp;#34; &amp;gt; &amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&amp;lt;/pattern&amp;gt; &amp;lt;/encoder&amp;gt; &amp;lt;topic&amp;gt;spring-boot-demo&amp;lt;/topic&amp;gt; &amp;lt;keyingStrategy class=&amp;#34;com.</description>
    </item>
    
    <item>
      <title>Ceph Ansible</title>
      <link>https://www.cheon.site/blog/struct/ceph_ansible/</link>
      <pubDate>Sun, 23 Jun 2019 16:45:52 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/ceph_ansible/</guid>
      <description>Ceph 介绍 无论是想要为云平台提供 Ceph Object Storage 或 Ceph Block Device 服务，部署一个 Ceph Filesystem 总是从设置每一个 Ceph 节点，网络和 Ceph 存储集群开始。一个 Ceph 存储集群至少需要一个 Ceph Monitor，Ceph Manger，和 Ceph OSD(Object Storage Daemon)。当运行 Ceph 文件系统客户端时也需要 Ceph Metadata Server。
 Monitors: 一个 Ceph 监视器(ceph-mon) 维护集群状态的映射，包括监视器，管理，OSD 和 CURSH 映射。这些映射是 Ceph 守护进程之间相互协调的关键。监视器还负责管理守护进程和客户端之间的身份验证。为了保证冗余和高可用，至少需要3个监视器。
 Mangers: 一个 Ceph 管理(ceph-mgr)守护进程负责保持追踪 Ceph 集群运行时指标和当前集群状态，包括存储利用率，当前的性能指标和系统负载。Ceph 管理进程还托管基于 python 的模块来管理和公开 Ceph 集群信息，包括一个基于网页的 Ceph Dashboard 和 REST API。为了保证高可用，至少需要2个管理节点。
 Ceph OSDs: 一个 Ceph OSD(object storage daemon, ceph-osd)存储数据，处理数据复制、恢复、重新平衡，并通过检查其他 Ceph OSD 进程的心跳来提供一些监控信息给 Ceph 监视器和管理。为了保证冗余和高可用，至少需要3个 Ceph OSDs。</description>
    </item>
    
    <item>
      <title>Nerd Font</title>
      <link>https://www.cheon.site/blog/system/nerd_font/</link>
      <pubDate>Fri, 21 Jun 2019 14:32:35 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/nerd_font/</guid>
      <description>图标字体 在用 dzen2 给桌面添加一个 panel 的时候用到了 FontAwesome，但是在 urxvt 终端下 FontAwesome 无法正常显示出来（不知是不是配置有误）。这样在用 vim 写脚本时不够直观。又不想换终端，所以只能从字体下手。
之前就了解到过 nerd-fonts 这个项目，可以将图标字体整合进一个你想要的字体中。项目主页提供了一些已经预先构建好的字体，可以在官网直接下载使用。目前终端用的字体是从另一台 Mac 上复制出来的 SFMono，这也是 Mac 内置终端默认的字体。已经习惯了这款字体后就不想换了，因此准备构建自己的字体。
根据项目主页的教程，执行它提供给你的 font-patcher 脚本前需要安装 fontforge:
pacman -S fontforge 安装完依赖，下载 font-patcher 脚本并添加可执行权限:
curl -OL https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/font-patcher chmod +x font-patcher 执行脚本进行构建字体:
./font-patcher path/to/SFMono-Regular.otf -out path/to/SFMono-Nerd/ -c -l -s  -c 表示添加所有可用字形 -l 表示适应行高（尝试将 powerline 的分隔符均匀地放在中间） -s 表示使用单个字符宽度  运行脚本发现报错，提示找不到 src 目录下的字体文件。这提示我们还需要去下载 src 目录下的字体文件。这里有一个技巧，关于如何从 github 下载某个文件夹。
以此处为例，需要下载https://github.com/ryanoasis/nerd-fonts/tree/master/src/glyphs目录下的所有字体文件。可以将 url 中的 &amp;ldquo;tree/master&amp;rdquo; 替换为 ”trunk“，再用 svn 去下载就好了。</description>
    </item>
    
    <item>
      <title>Ssh Config</title>
      <link>https://www.cheon.site/blog/solved/ssh_config/</link>
      <pubDate>Fri, 14 Jun 2019 17:22:12 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/ssh_config/</guid>
      <description>ssh 错误排查 新拿到的6台服务器，通过jumpserver用密钥登录到其中一台服务器，用 ssh 以账户密码的方式登录到其中另外一台服务器时遇见如下错误:
Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 测试登录另外一台服务器，发现可以正常登录；测试登录自己，报相同的错误。可以判断应该是 ssh 服务端配置有问题。
经过排查，发现应该是服务端没有开启密码认证，修改/etc/ssh/sshd_config，修改为如下配置，将no替换为yes:
PasswordAuthentication yes 保存配置重新启动 sshd 服务:
systemctl restart sshd 再次测试发现已经可以登录了</description>
    </item>
    
    <item>
      <title>Dockerfile Tips</title>
      <link>https://www.cheon.site/blog/shell/dockerfile_tips/</link>
      <pubDate>Thu, 13 Jun 2019 13:51:36 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/shell/dockerfile_tips/</guid>
      <description>Dockerfile 编写建议 日常编写Dockerfile的过程中总结的一些经验:
 基础镜像尽量选择alpine版本，减小镜像体积，如果需要glibc，在Dockerfile中添加以下指令
RUN apk --no-cache add ca-certificates wget &amp;amp;&amp;amp; \ wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;amp;&amp;amp; \ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.29-r0/glibc-2.29-r0.apk &amp;amp;&amp;amp; \ apk --no-cache add glibc-2.29-r0.apk  关于在alpine镜像中安装glibc，详情可以参考github介绍
 在Dockerfile里需要安装软件的尽量使用国内的源，加快ci构建，常见的操作如下：
 alpine:
RUN sed -i &amp;#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&amp;#39; /etc/apk/repositories debian:
curl -L &amp;#34;https://mirrors.ustc.edu.cn/repogen/conf/debian-https-4-buster&amp;#34; -o /etc/apt/sources.list centos:
RUN curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo node:
RUN npm install --registry=https://registry.npm.taobao.org \ &amp;amp;&amp;amp; npm config set phantomjs_cdnurl https://npm.taobao.org/dist/phantomjs \ &amp;amp;&amp;amp; npm config set chromedriver_cdnurl http://cdn.</description>
    </item>
    
    <item>
      <title>Es Clean Indices</title>
      <link>https://www.cheon.site/blog/shell/es_clean_indices/</link>
      <pubDate>Wed, 12 Jun 2019 16:00:30 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/shell/es_clean_indices/</guid>
      <description>ES 清理索引 使用阿里云的 ES 服务存储应用的日志，随着业务的增长和 ES 的资源限制，索引过多会引起 ES 的崩溃。 日志的采集是通过 logback 发送到 kafka，再用 logstash 消费 kafka 并转发给 ES。logstash 配置了%{[@metadata][kafka][topic]}-%{+YYYY-MM-dd}作为 ES 的索引。 经过讨论准备只将日志存储一个月，需要定时去清理索引，防止索引过多。
获取索引 首先要做的是获取当前的索引，通过查阅 ES 的 API 可知，可以用 /_cat/indices 接口来获取所有索引:
curl -X POST -s &amp;#34;http://es.example.site/_cat/indices&amp;#34; 可以看到如下结果:
green open test-app1-prod-log-2019-06-11 28NbwQbZTIaGPgb0S5Wkuw 5 1 189385 0 179.7mb 89.9mb green open test-app1-prod-log-2019-06-10 0EiQBNhZTnGZqUZ92J9UEg 5 1 189385 0 179.7mb 93.3mb green open test-app2-prod-log-2019-06-08 N_Th5gahSiu3kiycF26Q_A 5 1 2133105 0 4.5gb 2.2gb 需要将结果过滤一下，只保留 %{[@metadata][kafka][topic]} 的信息:</description>
    </item>
    
    <item>
      <title>Docker Graph Migrate</title>
      <link>https://www.cheon.site/blog/struct/docker_graph_migrate/</link>
      <pubDate>Tue, 14 May 2019 19:33:12 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/docker_graph_migrate/</guid>
      <description>docker 目录迁移 服务器根目录磁盘空间比较小，只有50G，在使用一段时间后镜像增多，磁盘不够用，准备将 docker 的目录挂载到新加的磁盘。挂载硬盘后如下：
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 3.7M 0 rom vda 253:0 0 50G 0 disk └─vda1 253:1 0 50G 0 part / vdb 253:16 0 200G 0 disk 创建 lvm 为了以后方便扩容，准备使用 lvm。首先创建 pv：
pvcreate /dev/vdb 创建 vg，命名为 docker：
vgcreate docker /dev/vdb 创建 lv，命名为 registry：
lvcreate -l +100%Free docker --name registry 将 lv 格式化为 xfs 文件系统：
mkfs.xfs /dev/docker/registry 替换目录 首先要将改节点的 pod 全都驱散走：</description>
    </item>
    
    <item>
      <title>C Sonarcloud</title>
      <link>https://www.cheon.site/blog/c/c_sonarcloud/</link>
      <pubDate>Mon, 06 May 2019 14:55:56 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/c/c_sonarcloud/</guid>
      <description>C 配置 Sonarcloud SonarQube 用于代码质量分析，可以检测出代码的 bug，代码异味，测试覆盖率等，有助于提高代码质量。SonarCloud 是 SonarQube 的在线使用版本，可以集成 github，travisCI。具体操作可以看官方文档。
之前写了一个终端管理 ssh 登录的小工具，想着检测一下代码质量，就想到用这个工具来检测一下。由于不需要每次提交都进行质量检测，所以没有集成到 CI 里面，而是在服务器上利用 SonarQube Scanner 手动执行。从检测结果来看，代码中确实有一些 bug 和代码异味。
安装 build wrapper 在下载页下载 linux 版的 build wrapper，解压出来应该有两个可执行文件。
build-wrapper-linux-x86/ ├── build-wrapper-linux-x86-32 ├── build-wrapper-linux-x86-64 ├── libinterceptor-i686.so └── libinterceptor-x86_64.so 可以将该目录加进PATH变量，方便调用。
安装 SonarQube Scanner 在下载页找到对应的平台，下载压缩包。解压后得到如下目录：
sonar-scanner-3.3.0.1492-linux ├── bin ├── conf ├── jre └── lib 可以将上面的bin目录添加到PATH环境变量中。
构建并分析代码 在项目的根目录下执行命令：
build-wrapper-linux-x86-64 --out-dir bw-output make export JAVA_TOOL_OPTIONS=&amp;#34;-Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=443 -Dhttps.proxyHost=127.0.0.1 -Dhttps.proxyPort=443&amp;#34; sonar-scanner \  -Dsonar.projectKey=number317_ssh-tool \  -Dsonar.</description>
    </item>
    
    <item>
      <title>Skywalking Deploy</title>
      <link>https://www.cheon.site/blog/struct/skywalking_deploy/</link>
      <pubDate>Thu, 25 Apr 2019 17:16:15 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/skywalking_deploy/</guid>
      <description>skywalking 部署 skywalking 是一个国产开源的调用链监控工具，可用于分析请求中哪些操作比较慢。官方提供了 k8s 的部署配置，但这个配置里的镜像是不对的，具体版本对应的镜像可以在Dockerhub上找到。如果想要更换版本，最好把 ES 中的索引先删除，否则可能会导致应用报错。
架构说明  elasticsearch: 用于存储 skywalking 数据，这里使用的是腾讯云的 ES 服务，因此无需搭建 skywalking-oap-server: skywalking 后端 ui: 默认 ui 界面 rocketbot-ui: skywalking 的另一个官方前端界面，没有现成的镜像，需要自己构建  部署 将官方的部署文件克隆到本地，将 oap， ui 的镜像换成对应的版本镜像。修改 oap 配置中的 ES 地址：
storage: elasticsearch: clusterNodes: elasticsearch:9200 先创建命名空间：
kubectl create ns skywalking 接着部署 oap 后端：
kubectl apply -f oap/ 再部署前端：
kubectl apply -f ui/ 为了集群外部访问，可以为前端配置一个域名或者在 service 中添加 externalIPs。
apiVersion: extensions/v1beta1 kind: Ingress metadata: generation: 1 name: ui namespace: skywalking spec: rules: - host: skywalking.</description>
    </item>
    
    <item>
      <title>Graylog Sidecar</title>
      <link>https://www.cheon.site/blog/struct/graylog_sidecar/</link>
      <pubDate>Wed, 14 Nov 2018 17:24:04 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_sidecar/</guid>
      <description>graylog sidecar 部署配置 graylog sidecar 用于配置从文件读取日志，具体读取文件可以采用filebeat和nxlog。这里在debian的容器中部署sidecar来示例。
安装sidecar 从下载页面下载对应的包，这里是debian系统，graylog版本是2.4。所以根据文档，下载collector-sidecar_0.1.7-1_amd64.deb：
curl -OL &amp;#34;https://github.com/Graylog2/collector-sidecar/releases/download/0.1.7/collector-sidecar_0.1.7-1_amd64.deb&amp;#34; 下载好后安装：
dpkg -i collector-sidecar_0.1.7-1_amd64.deb 安装好后配置system服务：
graylog-collector-sidecar -service install 这个命令会生成/etc/init.d/collector-sidecar脚步，但是在容器中可能systemctl命令执行不了，可以直接执行该脚本。
配置sidecar 编辑配置文件/etc/graylog/collector-sidecar，改为以下内容：
server_url: http://graylog.test.com/api/ update_interval: 10 tls_skip_verify: false send_status: true list_log_files: - /var/log/connect-check/ collector_id: file:/etc/graylog/collector-sidecar/collector-id cache_path: /var/cache/graylog/collector-sidecar log_path: /var/log/graylog/collector-sidecar log_rotation_time: 86400 log_max_age: 604800 tags: - connect-check backends: - name: nxlog enabled: false binary_path: /usr/bin/nxlog configuration_path: /etc/graylog/collector-sidecar/generated/nxlog.conf - name: filebeat enabled: true binary_path: /usr/bin/filebeat configuration_path: /etc/graylog/collector-sidecar/generated/filebeat.yml 主要是修改server_url和tags两项内容。
生存测试日志 编写一个脚本random.sh来生成一些测试日志：
#!/bin/bash while true; do flag=$RANDOM if [[ $flag -le 10923 ]]; then echo &amp;#34;Accept 200, connect checkout success.</description>
    </item>
    
    <item>
      <title>Graylog K8s Install</title>
      <link>https://www.cheon.site/blog/struct/graylog_k8s_install/</link>
      <pubDate>Wed, 14 Nov 2018 16:20:50 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_k8s_install/</guid>
      <description>graylog k8s 部署 graylog是一个日志聚合工具，用于统一展示应用日志。这里基于官方文档，在k8s集群中部署一套简单的单节点graylog服务。
mongodb 部署 mongodb 在服务中用于存储graylog的配置信息。以下是部署文件（没有进行数据持久化操作）：
 mongodb deploy
# {{{ deploy --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: graylog-mongo labels: app: graylog-mongo spec: replicas: 1 selector: matchLabels: app: graylog-mongo template: metadata: labels: app: graylog-mongo spec: containers: - name: graylog-mongo image: mongo:3 ports: - containerPort: 27017 protocol: TCP resources: limits: memory: 512Mi requests: memory: 100Mi terminationMessagePath: /dev/termination-log imagePullPolicy: IfNotPresent restartPolicy: Always terminationGracePeriodSeconds: 30 dnsPolicy: ClusterFirst securityContext: {} strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 0 maxSurge: 1 revisionHistoryLimit: 2 # }}} # {{{ service --- apiVersion: v1 kind: Service metadata: name: graylog-mongo labels: name: mongo spec: ports: - name: mongo protocol: TCP port: 27017 targetPort: 27017 selector: app: graylog-mongo type: ClusterIP sessionAffinity: None status: loadBalancer: {} # }}}</description>
    </item>
    
    <item>
      <title>Connection Reset Error</title>
      <link>https://www.cheon.site/blog/solved/connection_reset_error/</link>
      <pubDate>Fri, 19 Oct 2018 18:03:25 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/connection_reset_error/</guid>
      <description>k8s 应用接口请求 connection reset 错误 测试人员在进行压力测试时发现应用A的接口出现了 connection reset 的错误，出错率大概为十分之一，猜想可能是代码问题或是网络问题或是连接数限制问题。
问题排查 应用A有三个环境，dev，uat和prod。其中dev和uat在同一集群中，因此网络环境相同，在代码上，三个环境都是一样的。
 测试prod环境的同一接口，并没有出现相同错误，说明代码没有问题。 如果是连接数限制问题，那么应该不止此次压测出现，而之前几次压测都没有出现改问题，所以暂时先排除。 验证网络问题，测试应用B的一个静态文件请求，也发现了相同的错误，现在基本可以确定是网络问题。  原因查找 要想排查网络问题，要先了解一下系统的网络架构。
首先最外面是一个A10负载均衡，80端口代理到k8s集群三个master节点的80端口，所有的域名都解析在这个A10上。
三台master节点的ip地址和80端口被用作集群中ingress controller的service的externalIP，域名通过ingress controller找到对应的应用。
网络问题需要一层一层排查，首先是应用本身。用循环来发送100次请求，查看应用日志：
for i in {1..100}; do curl http://www.test.com/api/example; echo $i;done 通过日志发现请求出现connection reset时，应用没有对应日志，说明请求没有到应用这里。
应用上一层是域名，域名是通过ingress来配置的，查看ingress controller的日志，发现也没有报错日志，所以请求也没有到这里。
接下来查看三台master节点的80端口，发现其中一台master1的80端口不通。看来问题应该就出现在这里了，我们可以手动来验证一下。
将要请求的域名映射为master2的ip地址，在/etc/hosts中加入www.test.com master2IP，进行测试，发现没有出现错误。改成master1的ip地址则发现无法连接。
问题解决 查看了k8s集群的网络组件，发现master1上的flannel一直处于container creating状态。将pod删除重启，再次进行测试，发现connection reset的错误已经没了。</description>
    </item>
    
    <item>
      <title>Redis Somaxconn</title>
      <link>https://www.cheon.site/blog/solved/redis_somaxconn/</link>
      <pubDate>Mon, 13 Aug 2018 11:07:55 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/redis_somaxconn/</guid>
      <description>kubernetes redis 最大连接数设置 应用在进行压力测试的时候发现请求多（5000并发）的时候会报出redis连接超时错误，查看了redis的配置，发现如下配置：
# TCP listen() backlog. # # In high requests-per-second environments you need an high backlog in order # to avoid slow clients connections issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 从这个配置可以看到，reids的最大连接数配置了511，所以应该将这个配置调高。注释里有提醒这个配置会受到linux内核配置的限制，查看/proc/sys/net/core/somaxconn，发现这个值只有128，所以redis配置tcp-backlog 511并没有生效，实际值只有128。
由于这里的redis是通过kubernetes部署的，所以需要同时修改宿主机和容器的内核参数。由于集群中有许多主机，所以我们通过为三台节点添加标签和污点来搭建redis等中间件应用并且防止其他应用部署到这些节点。通过查阅资料发现要修改k8s部署的容器的内核参数，需要开启kubelet的配置。所以具体操作分为四步：</description>
    </item>
    
    <item>
      <title>Ansible Variables</title>
      <link>https://www.cheon.site/blog/struct/ansible_variables/</link>
      <pubDate>Fri, 25 May 2018 11:06:47 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/ansible_variables/</guid>
      <description>ansible 变量 ansible 变量以[A-Za-z]开头，可以包含下划线_和数字[0-9]，标准是全部使用小写字母。在清单(inventory)文件里，变量使用=赋值，如：
foo=bar 在剧本(playbook)或变量文件里，变量用:赋值，如：
foo: bar Playbook Variables 变量可以在使用ansible-playbook时通过命令行参数--extra-vars选项传递：
ansible-playbook example.yml --extra-vars &amp;#34;foo=bar&amp;#34; 也可以在参数中传递json，yaml格式的数据，甚至是json和yaml文件，就像--extra-vars &amp;quot;@even_more_vars.json&amp;quot;或者--extra-vars &amp;quot;@even_more_vars.yml&amp;quot;，但这种方式不建议使用。
变量可以直接在playbook中的vars部分定义：
--- - hosts: example vars: foo: bar tasks: # Prints &amp;#34;Variable &amp;#39;foo&amp;#39; is set to bar&amp;#34;. - debug: msg=&amp;#34;Variable &amp;#39;foo&amp;#39; is set to {{ foo }}&amp;#34; 变量也可以在单独的文件中定义，然后在playbook中通过vars_files引用：
# Main playbook file. - hosts: example vars_files: - vars.yml tasks: - debug: msg=&amp;#34;Variable &amp;#39;foo&amp;#39; is set to {{ foo }}&amp;#34; 和playbook同目录下的vars.yml：
# Variables file &amp;#39;vars.</description>
    </item>
    
    <item>
      <title>Vps Openvpn</title>
      <link>https://www.cheon.site/blog/system/vps_openvpn/</link>
      <pubDate>Sat, 28 Apr 2018 15:22:21 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/vps_openvpn/</guid>
      <description>VPS OpenVPN 翻墙教程 服务端配置 首先，需要一台能访问外网的服务器。这里采用的是HostUS的VPS。
在部署OpenVPN服务端之前，应该先打开服务器的ip转发功能。修改/etc/sysctl.conf文件，将对应内容修改为下面一行的值：
net.ipv4.ip_forward = 1 修改后执行sysctl -p /etc/sysctl.conf使配置生效。
服务端采用容器部署，因此VPS应该先安装好docker。以下为容器启动脚本：
#!/bin/bash IP=&amp;#34;xxx.xxx.xxx.xxx&amp;#34; OVPN_DATA=&amp;#34;/root/ovpn_data&amp;#34; docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://$IP docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki docker run -v $OVPN_DATA:/etc/openvpn --name openvpn -e DEBUG=1 -d -p 1194:1194/udp --cap-add=NET_ADMIN kylemanna/openvpn docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full CLIENTNAME nopass docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient CLIENTNAME &amp;gt; CLIENTNAME.ovpn 将上述脚本的IP地址替换为自己的IP地址，然后执行脚本，根据提示输入信息即可。中间要求输入密码之类的都写个简单点一样的密码就好。
脚本执行完成后会生成一个CLIENTNAME.ovpn客户端的配置文件，将它下载到自己的电脑上，用于配置客户端。</description>
    </item>
    
    <item>
      <title>Iptables Intro</title>
      <link>https://www.cheon.site/blog/system/iptables_intro/</link>
      <pubDate>Thu, 26 Apr 2018 08:32:31 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/iptables_intro/</guid>
      <description>iptables 介绍 基本概念  iptables 可以检测、修改、转发、重定向和丢弃IPV4数据包。 表(tables)  raw: 用于配置数据包 filter: 存放所有与防火墙相关操作的表 nat: 用于网络地址转换 mangle: 用于对特定数据包的修改 security: 用于强制访问控制  链(chains): INPUT, OUTPUT, FORWARD, PREROUTING,POSTROUTING 规则(rules): 过滤数据包 模块(modules): 用于扩展iptables，进行更复杂的过滤  工作流程 第一个路由策略包括决定数据包的目的地是本地主机（这种情况下，数据包穿过 INPUT 链），还是其他主机（数据包穿过 FORWARD 链）；
中间的路由策略包括决定给传出的数据包使用那个源地址、分配哪个接口；
最后一个路由策略存在是因为 mangle 与 nat 链可能会改变数据包的路由信息。
数据包通过路径上的每一条链时，链中的每一条规则按顺序匹配；无论何时匹配了一条规则，相应的 target/jump 动作将会执行。最常用的3个 target 是 ACCEPT, DROP ,或者 jump 到用户自定义的链。内置的链有默认的策略，但是用户自定义的链没有默认的策略。在 jump 到的链中，若每一条规则都不能提供完全匹配，那么数据包返回到调用链。在任何时候，若 DROP target 的规则实现完全匹配，那么被匹配的数据包会被丢弃，不会进行进一步处理。如果一个数据包在链中被 ACCEPT，那么它也会被所有的父链 ACCEPT，并且不再遍历其他父链。然而，要注意的是，数据包还会以正常的方式继续遍历其他表中的其他链。
常用选项    参数类型 可选项     表 filter, nat&amp;hellip;   链 INPUT, OUTPUT, FORWARD, PREOUTING（修改目标ip地址）, POSTROUTING（修改源ip地址）&amp;hellip;   匹配属性 源、目标IP，协议（TCP,UDP,ICMP&amp;hellip;），端口号，网卡接口&amp;hellip;   模块 conntrack, multiport, connlimit&amp;hellip;   动作 ACCEPT, DROP, RETURN, REJECT&amp;hellip;    配置运行 # systemctl start iptables 启动时会读取/etc/iptables/iptables.</description>
    </item>
    
    <item>
      <title>Interesting Shell Commands</title>
      <link>https://www.cheon.site/blog/shell/interesting_shell_commands/</link>
      <pubDate>Wed, 25 Apr 2018 18:16:49 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/shell/interesting_shell_commands/</guid>
      <description>一些有意思的shell命令 $ printf &amp;#34;%x&amp;#34; \&amp;#39;$ $ printf \\x2F 将字符转化为16进制(%x), 十进制(%d)&amp;hellip; 第二个命令将16进制转化为字符
$ python -m SimpleHTTPServer $ python -m http.server 使用python来建立一个简易的web service用于文件传输，第一个时python2的写法，后一个是python3的写法，默认端口为8000，可以在后面直接加端口指定端口
$ nc -l localhost -p 1016 $ nc localhost 1016 $ nc -lu localhost -p 8125 $ nc -u localhost 8125 gnu-netcat软件包，使用nc命令监听1016端口，然后再用nc可以发送数据，这可以用于文件传输，做简易的聊天工具
curl -OL https://github.com/cmderdev/cmder/releases/download/v1.3.2/cmder.zip curl -Ss &amp;#34;https://store.docker.com/api/content/v1/repositories/public/library/$@/tags?page_size=25&amp;amp;page=1&amp;#34; | jq &amp;#39;.&amp;#34;results&amp;#34;[][&amp;#34;name&amp;#34;]&amp;#39; | sort -r curl -X POST -H &amp;#34;Content-Type: application/json&amp;#34; -H &amp;#34;Authorization: Basic YWRtaW46YWRtaW4xMjM=&amp;#34; &amp;#39;http://localhost:8081/service/siesta/rest/v1/script/&amp;#39; \  -d &amp;#39;{ &amp;#34;name&amp;#34;: &amp;#34;updateAnonymousAccess&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;groovy&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;security.</description>
    </item>
    
    <item>
      <title>Firefox Open Markdown</title>
      <link>https://www.cheon.site/blog/solved/firefox_open_markdown/</link>
      <pubDate>Tue, 17 Apr 2018 01:17:33 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/firefox_open_markdown/</guid>
      <description>使用firefox打开并渲染markdown 如果用firefox打开markdown文件只有下载选项，需要更新mime的数据库:
在~/.local/share/mime/packages目录下创建text-markdown.xml文件，内容如下
&amp;lt;?xml version=&amp;#34;1.0&amp;#34;?&amp;gt; &amp;lt;mime-info xmlns=&amp;#39;http://www.freedesktop.org/standards/shared-mime-info&amp;#39;&amp;gt; &amp;lt;mime-type type=&amp;#34;text/plain&amp;#34;&amp;gt; &amp;lt;glob pattern=&amp;#34;*.md&amp;#34;/&amp;gt; &amp;lt;glob pattern=&amp;#34;*.mkd&amp;#34;/&amp;gt; &amp;lt;glob pattern=&amp;#34;*.markdown&amp;#34;/&amp;gt; &amp;lt;/mime-type&amp;gt; &amp;lt;/mime-info&amp;gt; 然后执行update-mime-database ~/.local/share/mime
完成后即可用firefox打开markdown文件。若想要查看markdown的渲染效果，可以安装markdown的插件，如markdow viewer webext等</description>
    </item>
    
    <item>
      <title>Dell Xps 15 9560 Arch Linux Install</title>
      <link>https://www.cheon.site/blog/system/dell_xps_15_9560_arch_linux_install/</link>
      <pubDate>Wed, 28 Mar 2018 10:18:12 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/dell_xps_15_9560_arch_linux_install/</guid>
      <description>Dell XPS 15 9560 Arch Linux 安装教程 BIOS设置 打开电脑，等待出现dell图标时按下F12键，选择进入BIOS设置页面，进行如下操作
 将SATA Mode从默认的RAID模式修改为AHCI模式。这样可以允许Linux检测到NVME SSD。 将Fastboot的选项从POST Behaviour修改为Thorough，这样可以防止偶尔的启动错误。 关闭安全启动来允许linux启动。  保存后退出，会重启电脑。
内核启动参数设置 从U盘启动 Arch Linux 引导镜像：在dell图标出现时按下F12，选择从U盘启动，在出现启动菜单时，按下e键，添加以下启动参数：
initrd=\initramfs-linux.img root=/dev/sdb2 acpi_rev_override=1 pci=nommconf nouveau.modeset=0 这样可以保证系统可以正常关闭和重启，否则关闭和重启时电脑会死机。
系统安装 tty字体设置 首先由于4k屏的高分辨率，使得终端字体非常小，应该设置大一点的字体：
setfont latarcyrheb-sun32 网络连接 wifi-menu 根据提示选择wifi，输入密码即可。
分区 这里采用lvm并使用cryptsetup来加密磁盘，最终分区如下：
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:0 0 477G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot └─nvme0n1p2 259:2 0 476.4G 0 part └─luks 254:0 0 476.4G 0 crypt ├─entropy--vg0-root 254:1 0 150G 0 lvm / ├─entropy--vg0-home 254:2 0 250G 0 lvm /home ├─entropy--vg0-swap 254:3 0 16G 0 lvm [SWAP] └─entropy--vg0-backup 254:4 0 10G 0 lvm  磁盘创建两个分区，一个分区用于/boot，另一个分区用于安装系统。</description>
    </item>
    
    <item>
      <title>Openshift Restart Node</title>
      <link>https://www.cheon.site/blog/solved/openshift_restart_node/</link>
      <pubDate>Thu, 08 Mar 2018 18:09:41 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/openshift_restart_node/</guid>
      <description>openshift 节点无法连接集群 在openshift master 节点上执行oc get node:
$ oc get node NAME STATUS AGE node1 NotReady,SchedulingDisabled 301d master1 Ready 308d master2 Ready 308d master3 Ready 308d master4 Ready 308d master5 Ready 31d 其中的node1状态为NotReady,SchedulingDisabled，改节点没有准备好，并且是无法调度的，其中无法调度是手动设置的：
$ openshift admin manage-node node1 --schedulable=false 重启origin-node服务，让节点重新连接集群：
$ systemctl restart origin-node 重新查看节点状态：
$ oc get node NAME STATUS AGE node1 Ready,SchedulingDisabled 301d master1 Ready 308d master2 Ready 308d master3 Ready 308d master4 Ready 308d master5 Ready 31d 节点已经 ready，再将其设置为可调度的：</description>
    </item>
    
    <item>
      <title>Tomcat Deploy Error</title>
      <link>https://www.cheon.site/blog/solved/tomcat_deploy_error/</link>
      <pubDate>Tue, 06 Feb 2018 18:44:13 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/solved/tomcat_deploy_error/</guid>
      <description>tomcat部署war包出错 错误1 错误日志如下：
Caused by: java.lang.IllegalStateException: Unable to complete the scan for annotations for web application [/capitalplan] due to a StackOverflowError. Possible root causes include a too low setting for -Xss and illegal cyclic inheritance dependencies. The class hierarchy being processed was [org.bouncycastle.asn1.ASN1EncodableVector-&amp;gt;org.bouncycastle.asn1.DEREncodableVector-&amp;gt;org.bouncycastle.asn1.ASN1EncodableVector] at org.apache.catalina.startup.ContextConfig.checkHandlesTypes(ContextConfig.java:2099) at org.apache.catalina.startup.ContextConfig.processAnnotationsStream(ContextConfig.java:2043) at org.apache.catalina.startup.ContextConfig.processAnnotationsJar(ContextConfig.java:1989) at org.apache.catalina.startup.ContextConfig.processAnnotationsUrl(ContextConfig.java:1959) at org.apache.catalina.startup.ContextConfig.processAnnotations(ContextConfig.java:1912) at org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1154) at org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:771) at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:298) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:94) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5093) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:152) ... 10 more 解决方案：</description>
    </item>
    
    <item>
      <title>Lvm Intro</title>
      <link>https://www.cheon.site/blog/system/lvm_intro/</link>
      <pubDate>Fri, 26 Jan 2018 15:27:50 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/lvm_intro/</guid>
      <description>LVM 介绍 LVM(Logical Volume Management)逻辑卷管理利用linux内核的device-mapper特征来实现存储系统的虚拟化，操作系统不再直接操作磁盘，而是操作LV(Logical Volume)逻辑卷。
传统磁盘管理如GPT分区和MBR分区存在着磁盘分区无法动态扩展的缺点，即是增加新的磁盘也只能当作单独的文件系统使用，而无法为已在使用的分区增加空间。LVM正好解决了这个问题，可以动态地为分区扩容，而不影响上层系统的使用。
LVM 基本概念  PE(Physical Extend)：物理区域&amp;ndash;逻辑卷管理的最小单位，默认大小为4M PV(Physical Volume)：物理卷&amp;ndash;建立卷组的媒介，可以是磁盘，分区或者回环文件，物理卷包括一个特殊的header，其余部分被切割为一块块物理区域(physical extents) VG(Volume Group)：卷组&amp;ndash;物理卷组成的组，可以被认为是PE池 LV(Logical Volume)：逻辑卷&amp;ndash;虚拟分区，由PE组成。组成LV的PE可以来自不同的磁盘  LVM 工作流程 构造逻辑卷LV主要有3个步骤：
 将磁盘或分区条带化为PV(物理卷)，实际上是将磁盘或分区分割成一个个PE(物理区域)，默认大小是4M 将PV组合成VG，VG中的PE供LV使用，创建VG时需要给VG命名，/dev/目录下会生成一个以VG名字命名的文件夹 基于VG创建LV，LV也需要命名，LV创建好后会在对应的卷组目录下创建一个一LV名字命名的设备，该设备呈现给操作系统使用，可以格式化，当作正常的分区使用。  Physical disks Disk1 (/dev/sda): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Partition1 50GB (Physical Volume) |Partition2 80GB (Physical Volume) | |/dev/sda1 |/dev/sda2 | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ | Disk2 (/dev/sdb): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Partition1 120GB (Physical Volume) | |/dev/sdb1 | | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __ _ _| LVM logical volumes Volume Group1 (/dev/MyStorage/ = /dev/sda1 + /dev/sda2 + /dev/sdb1): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Logical volume1 15GB |Logical volume2 35GB |Logical volume3 200GB | |/dev/MyStorage/rootvol|/dev/MyStorage/homevol |/dev/MyStorage/mediavol | |_ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ | 如上图中有/dev/sda，/dev/sdb两个磁盘，sda有sda1和sda2两个分区，sdb有sdb1一个分区，三个分区都被条带化成了PV。三个PV组成了一个VG，名字是MyStorage，基于这个VG创建了三个LV，分别叫做rootvol，homevol，mediavol，在/dev/目录下也创建了相应的文件夹和设备。</description>
    </item>
    
    <item>
      <title>Redhat Enable Ipv6</title>
      <link>https://www.cheon.site/blog/system/redhat_enable_ipv6/</link>
      <pubDate>Fri, 26 Jan 2018 14:43:54 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/system/redhat_enable_ipv6/</guid>
      <description>RedHat设置开机启用ipv6 参照的系统信息：
$ lsb_release -a LSB Version: :core-4.1-amd64:core-4.1-noarch Distributor ID: RedHatEnterpriseServer Description: Red Hat Enterprise Linux Server release 7.3 (Maipo) Release: 7.3 Codename: Maipo 首先查看系统是否开启了ipv6：
ifconfig | grep inet 或者
ip addr | grep inet 如果开启了，则应该有ipv6的字段：
inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0 inet6 fe80::a00:27ff:fe3a:b67/64 scope link inet 192.168.33.10/24 brd 192.168.33.255 scope global eth1 inet6 fe80::a00:27ff:fef4:9024/64 scope link inet 172.</description>
    </item>
    
    <item>
      <title>Glusterfs Deploy</title>
      <link>https://www.cheon.site/blog/struct/glusterfs_deploy/</link>
      <pubDate>Tue, 09 Jan 2018 10:09:35 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/glusterfs_deploy/</guid>
      <description>glusterfs centos 部署 GlusterFS是一个开源的分布式文件系统，这里部署它主要为了解决文件存储的单点问题。
虚拟机配置 此处采用vagrant部署centos的虚拟机三台，box可以采用bento/centos7.2，配置文件如下：
Vagrant.configure(&amp;#34;2&amp;#34;) do |config| (1..3).each do |i| config.vm.define &amp;#34;gluster-node#{i}&amp;#34; do |node| file_to_disk = &amp;#34;tmp/gluster_node#{i}_disk.vdi&amp;#34; node.vm.box = &amp;#34;centos-7.2&amp;#34; node.vm.hostname = &amp;#34;gluster-node#{i}&amp;#34; n = 100 +i node.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.12.#{n}&amp;#34; node.vm.provider &amp;#34;virtualbox&amp;#34; do |vb| unless File.exist?(file_to_disk) vb.customize [&amp;#39;createhd&amp;#39;, &amp;#39;--filename&amp;#39;, file_to_disk, &amp;#39;--size&amp;#39;, 10 * 1024] vb.customize [&amp;#39;storageattach&amp;#39;, :id, &amp;#39;--storagectl&amp;#39;, &amp;#39;SATA Controller&amp;#39;, &amp;#39;--port&amp;#39;, 1, &amp;#39;--device&amp;#39;, 0, &amp;#39;--type&amp;#39;, &amp;#39;hdd&amp;#39;, &amp;#39;--medium&amp;#39;, file_to_disk] end vb.name = &amp;#34;gluster-node#{i}&amp;#34; vb.cpus = 1 vb.memory = 1024 end end end end 该配置文件根据官方quick start文档，为虚拟机配置了第二磁盘，用于GlusterFS存储，大小为10G。</description>
    </item>
    
    <item>
      <title>Fluentd Config</title>
      <link>https://www.cheon.site/blog/struct/fluentd_config/</link>
      <pubDate>Fri, 05 Jan 2018 10:14:58 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/fluentd_config/</guid>
      <description>命令列表 Fluentd配置文件由以下配置文件组成：
 source命令 指明数据输入源 match命令 指明数据输出源 filter命令 指明事件处理的管道 system命令 指明系统级别配置 label命令 为输出分组并过滤内部路由 include命令 包含其他文件  命令详解  source: 数据的来源
Fluentd的输入源通过source命令选择和配置想要的输入插件来启用。Fluentd的标准输入插件包括http和forward。http使得Fluentd转变为一个HTTP终端用于接收到来的HTTP信息，而forward将fluentd转变为一个TCP终端用于接收TCP包。当然，它们可以被同时启用。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.host:9880/myapp.access?json={&amp;#34;event&amp;#34;:&amp;#34;data&amp;#34;} &amp;lt;source&amp;gt; @type http port 9880 &amp;lt;/source&amp;gt; 每一个source命令必须包含一个type参数。type参数指定使用哪一个输入插件。
 match: 告诉fluentd做什么
match命令寻找匹配标签的事件并且处理它们。match命令最常见的用法是将事件输出到其他系统（由于这个原因，这些插件被称为”输出插件“）。Fluentd的标准输出插件包括file和forward。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.</description>
    </item>
    
    <item>
      <title>K8s Cluster Deploy</title>
      <link>https://www.cheon.site/blog/struct/k8s_cluster_deploy/</link>
      <pubDate>Mon, 04 Dec 2017 09:19:26 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/k8s_cluster_deploy/</guid>
      <description>vagrant kubernetes 集群部署 集群说明 集群共有四个节点，一个master节点，四个子节点，其中一个节点即是master节点，也是node节点，系统均为centos-7.2。
k8s-node1 192.168.12.81 master, node k8s-node2 192.168.12.82 node k8s-node3 192.168.12.83 node k8s-node4 192.168.12.84 node vagrant 配置 vagrant 的 box 可选用 bento/centos-7.2:
 Vagrantfile
# -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The &amp;#34;2&amp;#34; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don&amp;#39;t change it unless you know what # you&amp;#39;re doing.</description>
    </item>
    
    <item>
      <title>Maven &amp; Nexus</title>
      <link>https://www.cheon.site/blog/struct/maven_nexus/</link>
      <pubDate>Thu, 09 Nov 2017 10:47:30 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/maven_nexus/</guid>
      <description>maven 配置使用 nexus 私服 修改~/.m2/settings.xml内容如下：
 mvn config
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;settings xmlns=&amp;#34;http://maven.apache.org/SETTINGS/1.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&amp;#34;&amp;gt; &amp;lt;servers&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;releases&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;thirdpart&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;/servers&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;central&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;central&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public/&amp;lt;/url&amp;gt; &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; &amp;lt;/settings&amp;gt; 
在项目的 pom.xml 文件中添加如下内容：
 pom config
&amp;lt;distributionManagement&amp;gt; &amp;lt;snapshotRepository&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Snapshot Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/snapshots/&amp;lt;/url&amp;gt; &amp;lt;/snapshotRepository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;releases&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Release Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/releases/&amp;lt;/url&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;/distributionManagement&amp;gt; &amp;lt;repositories&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;public&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Public&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Snapshots&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/snapshots&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;thirdparty&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;3rd party&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/thirdparty/&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;/repositories&amp;gt; &amp;lt;pluginRepositories&amp;gt; &amp;lt;pluginRepository&amp;gt; &amp;lt;id&amp;gt;public&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Plugin Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;layout&amp;gt;default&amp;lt;/layout&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/pluginRepository&amp;gt; &amp;lt;/pluginRepositories&amp;gt;</description>
    </item>
    
    <item>
      <title>Etcd &amp; Flannel</title>
      <link>https://www.cheon.site/blog/struct/etcd_and_flannel/</link>
      <pubDate>Wed, 01 Nov 2017 17:58:29 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/etcd_and_flannel/</guid>
      <description>etcd &amp;amp; flannel 实现跨主机容器通信 准备工作  测试环境：vagrant + centos7.2 虚拟机 主机说明：  ip: 192.168.12.101 hostname: node1 安装软件：etcd, flannel, docker ip: 192.168.12.102 hostname: node2 安装软件：flannel, docker   启动虚拟机 vagrant配置文件：
 Vagrantfile
# -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(2) do |config| (1..2).each do |i| config.vm.define &amp;#34;node#{i}&amp;#34; do |s| s.vm.box = &amp;#34;bento/centos-7.2&amp;#34; s.vm.hostname = &amp;#34;node#{i}&amp;#34; n = 100 + i s.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.12.#{n}&amp;#34; s.ssh.username = &amp;#34;vagrant&amp;#34; s.</description>
    </item>
    
    <item>
      <title>Rabbitmq Access Control</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_access_control/</link>
      <pubDate>Mon, 30 Oct 2017 09:48:14 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_access_control/</guid>
      <description>Rabbitmq 权限控制 在rabbitmq中，身份验证和授权是分开的。身份验证用于判断用户是谁，授权用于确定用户能做什么和不能做什么。
默认虚拟主机和用户 当服务第一次启动或者检测到数据库梅雨初始化或已经被删除，rabbitmq会初始化一个新的数据库，拥有如下资源：
 一个虚拟主机/ 一个用户名和密码都为guest的用户，拥有/虚拟主机的所有权限  建议是删除默认用户或者修改默认用户的密码。guest用户默认情况只能通过localhost连接，无法通过远程连接。这可以通过配置文件修改，设置loopback_users.guest = false即可。
权限工作方式 rabbitmq的权限控制主要分为两层，第一层是虚拟主机的权限，第二层是资源的权限。
虚拟主机(Virtual Host) 当客户端连接到服务器，它会指定一个要操作的虚拟主机，第一层权限控制被启用，服务器会检查用户对该虚拟主机是否有权限，没有权限连接会被拒绝。
示例：
首先创建一个用户：
rabbitmqctl add_user cheon 123 这里创建了一个用户cheon，密码为123（如果rabbitmq是集群，那么在集群中一个节点上创建了用户，虚拟主机等，在其他节点上也都会存在。）。刚创建的用户是没有任何权限的。可以确认一下用户的权限：
root@rabbitmq-node1:/# rabbitmqctl list_user_permissions cheon Listing permissions for user &amp;#34;cheon&amp;#34; ... root@rabbitmq-node1:/# rabbitmqctl list_user_permissions guest Listing permissions for user &amp;#34;guest&amp;#34; ... /	.*	.*	.* 可以看到新用户cheon没有任何权限，guest用户拥有虚拟主机/的全部权限。
编写一个简单的脚本，通过用户cheon连接/虚拟主机，发送Hello World：
#!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, &amp;#34;/&amp;#34;, credentials=pika.PlainCredentials(&amp;#39;cheon&amp;#39;, &amp;#39;123&amp;#39;))) channel = connection.channel() channel.queue_declare(queue=&amp;#39;hello&amp;#39;) channel.basic_publish( exchange=&amp;#39;&amp;#39;, routing_key=&amp;#39;hello&amp;#39;, body=&amp;#39;Hello World!</description>
    </item>
    
    <item>
      <title>Rabbitmq Topic</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_topic/</link>
      <pubDate>Sun, 29 Oct 2017 20:32:52 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_topic/</guid>
      <description>rabbitmq 主题 虽然之前使用了direct交换来路由不同级别的日志，但是它无法做到根据设备来路由。在我们的日志系统中，可能不止是想要通过日志级别来订阅，还想通过日志来源订阅。这将会给我们带来更大的灵活性，比如我们可以只监听来自cron的error和来自kern的所有日志。为了达到这个效果，我们可以采用一个更复杂的交换&amp;ndash;topic。
Topic exchange 发送给topic交换的信息的routing_key的属性不能是任意的&amp;ndash;它必须是一个单词的列表，通过.分隔。单词可以是任意的，但是通常是一些描述信息特征的词语。例如stock.usd.nyse，nyse.vmw，quick.orange.rabbit。你可以设置任意多的词语，只要不超过255字节的限制。
binding key也必须是相同的格式。topic背后的交换逻辑和direct是相似的，一个带有特殊routing key的信息会被发送到所有拥有匹配binding key的队列，但有两个需要注意的地方：
 * 可以代表一个单词 # 可以代表0或多个单词  示例：
在这个示例中，我们发送描述动物的消息。消息会带有由三个单词组成的routing key，单词间用.分隔，用于描述不同的特征。我们创建了三个绑定：Q1和*.orange.*绑定，Q2和*.*.rabbit，lazy.#绑定。可以简单得概括为Q1只关心所有橙色的动物，Q2只关心兔子和慢吞吞的动物。
一条带有quick.orange.rabbit的routing key的信息会发送给两个队列，quick.orange.fox也会发送给两个，lazy.brown.fox只发送给Q2，lazy.pink.rabbit只发送给Q2一次，即使它匹配了两个绑定。quick.brown.fox不匹配任何绑定所以会被丢弃。如果我们发送的信息带有一个或四个单词，像orange，quick.orange.male.rabbit之类的，也不匹配任何绑定，也会被丢弃 。但是lazy.orange.male.rabbit虽然有四个单词，也匹配lazy.#，因为#代表0或多个单词，所以会被发送给Q2。
topic是一个强大的交换，可以实现其他交换的功能。当一个队列绑定#，它可以接收所有信息，就像fanout交换。当没有使用*和#，而是指定明确的字符串，就可以表现地像direct交换。
最终实现 我们假设日志的routing key有两个单词&amp;lt;facility&amp;gt;.&amp;lt;severity&amp;gt;，那么代码如下：
emit_log_topic.py：
#!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, credentials=pika.PlainCredentials(&amp;#39;guest&amp;#39;, &amp;#39;guest&amp;#39;))) channel = connection.channel() channel.exchange_declare( exchange=&amp;#39;topic_logs&amp;#39;, exchange_type=&amp;#39;topic&amp;#39; ) severity = sys.argv[1] if len(sys.argv) &amp;gt; 2 else &amp;#39;info&amp;#39; message = &amp;#39; &amp;#39;.join(sys.argv[2:]) or &amp;#39;Hello World!&amp;#39; channel.basic_publish( exchange=&amp;#39;topic_logs&amp;#39;, routing_key=severity, body=message ) print(&amp;#34; [x] Sent %r:%r&amp;#34; % (severity, message)) connection.</description>
    </item>
    
    <item>
      <title>Rabbitmq Routing</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_routing/</link>
      <pubDate>Sat, 28 Oct 2017 09:26:49 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_routing/</guid>
      <description>Rabbitmq 路由 这里我们将为日志系统增加一个特性&amp;ndash;只订阅一部分信息。例如，我们可以将错误信息存入日志文件，将其他信息打印出来。
绑定（Bindings） 在日志系统中我们已经使用过绑定，像这样调用代码：
channel.queue_bind( exchange=exchange_name, queue=queue_name ) 一个绑定是交换和队列之间的关系，可以简单地理解为这个队列只对这个交换的信息感兴趣。绑定可以指定额外的routing_key参数。为了避免和一个basic_publish参数混淆，我们称它binding key，可以通过一下方式创建一个带有key的绑定：
channel.queue_bind( exchange=exchange_name, queue=queue_name, routing_key=&amp;#39;black&amp;#39; ) binding key的含义依赖于交换的类型。fanout交换类型会直接忽略这个值。
Direct exchange 我们之前的日志系统使用fanout交换类型，直接将信息广播给所有消费者。现在我们想要扩展它允许根据根据级别来过滤。例如，将错误级别的日志存入磁盘，将普通的日志直接输出而不浪费磁盘空间。为了达到这个目的，这里将使用direct交换。direct交换的路由算法也比较简单，一个消息只推送到binding key和routing key匹配的队列，举例如下图：
在上述例子中可以看到direct交换x有两个与之绑定的队列。第一个队列的binding key是orange，第二个队列有两个binding key，分别是black和green。通过这个配置，一个带有orage的routing key的信息推送到交换后会被路由到队列Q1；一个带有black或者green的routing key的信息推送到交换后会被路由到队列Q2，其他的信息会被丢弃。
多绑定（Muliple bindings） 用相同的binding key绑定多个队列完全是可行的。在我们的例子中可以在x和Q1之间添加一个名为black的binding key，这样的话，direct交换将会表现得像fanout并且会将信息广播到所有匹配的队列。一个带有black的routing key的信息会递送到Q1和Q2队列。
发送日志 我们将使用这个模型来构建日志系统，我们将会发送信息到direct交换，我们将会以日志的级别作为routing key。首先创建交换：
channel.exchange_declare( exchange=&amp;#39;direct_logs&amp;#39;, exchange_type=&amp;#39;direct&amp;#39; ) 然后发送消息：
channel.basic_publish( exchange=&amp;#39;direct_logs&amp;#39;, routing_key=serverity, body=message ) 为了简化程序，我们假设日志级别只有info，warning，error三种情况。
订阅 我们将为每一个需要的日志级别创建一个新的绑定：
result = channel.queue_declare(exclusive=True) queue_name = result.method.queue for severity in severities: channel.queue_bind( exchange=&amp;#39;direct_logs&amp;#39;, queue=queue_name, routing_key=severity ) 最终结果 emit_log_direct.py：
#!/usr/bin/env python import pika import sys connection = pika.</description>
    </item>
    
    <item>
      <title>Rabbitmq Publish Subscribe</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_publish_subscribe/</link>
      <pubDate>Fri, 27 Oct 2017 15:18:38 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_publish_subscribe/</guid>
      <description>Publish Subcribe 发布和订阅模式简单而言就是将一个消息发送个多个消费者。为了阐明这个模式，这里将会构建一个简单的日志系统，这个系统由两部分组成，第一个程序发送消息，第二个程序接收和打印消息。
在该日志系统中，接收程序的每一个运行副本都将得到消息，这样我们可以运行一个接收器，并将日志存放在磁盘；同时运行另一个接收器将日志在屏幕上打印出来。
交换(Exchanges) rabbitmq 消息模型的核心是生产者从不直接发送任何消息到队列。事实上，一个生产者经常不知道一个消息是否被发送到了队列。生产者只能将消息发送给交换。交换是一个非常简单的东西，它一边接收来自生产者的消息，另一边它把消息推入消息队列。交换是一定知道要怎么处理它接收到的消息的。应该被追加到一个特定的队列后，还是应该追加到多个队列中，还是应该被丢弃。这些规则都由交换类型（exchange type）定义。
有一些可用的交换类型：direct, topic, headers 和 fanout，这里将使用最后一个类型&amp;ndash;fanout。创建一个名为logs的该类型交换：
channel.exchange_declare(exchange=&amp;#39;logs&amp;#39;, exchange_type=&amp;#39;fanout&amp;#39;) fanout类型的交换非常简单。就如它的名字一样，它只是将它接收到的信息广播到它知道的所有队列，这正是我们日志系统所需要的。
查看交换 列出服务器上可用的交换可以使用rabbitmqctl命令:
rabbitmqctl list_exchanges 在列表中会有一些amq.*的交换和默认（未命名）的交换。这些是默认配置的，但是这里目前用不到他们。
有时候我们通过空字符串&#39;&#39;来使用默认的交换：
channel.basic_publish(exchange=&amp;#39;&amp;#39;, routing_key=&amp;#39;hello&amp;#39;, body=message) 现在我们可以推送到我们的命名交换中：
channel.basic_publish( exchange=&amp;#39;logs&amp;#39; routing_key=&amp;#39;&amp;#39;, body=message ) 临时队列 有时我们使用的队列有指定的名字，能够为队列命名是至关重要的，我们需要指定工作到相同的队列。当你想要在生产者和消费者间共享队列时为队列命名是很重要的。但是在我们的日志系统中，我们想要监听所有的日志，而不是一些；我们也只对当前流动的信息感兴趣而不是旧的信息。要达到这个效果我们需要两件事。
第一，无论何时连接到rabbitmq我们需要刷新，清空队列。为了做到这个我们可以用随机名字创建一个队列，或者更好的是让服务器为我们选择一个随机的队列名字。可以通过不给queue参数到queue_declare来做到这一点：
result = channel.queue_declare() 这个时候result.method.queue包含了一个随机的队列名。例如它可能看起来像amq.gen-JzTY20BRgKO-HjmUJj0wLg
第二，一旦消费者连接被关闭，队列应该被删除，有一个exclusive标签：
result = channel.queue_declare(excusive=True) 可以在队列指南获取更多exclusive标签和其他队列属性。
绑定（Bindings） 我们已经创建了一个fanout类型的交换。现在我们需要告诉交换发送信息给我们的队列。交换和队列之间的关系叫做绑定：
channel.queue_bind(exchange=&amp;#39;logs&amp;#39;, queue=result.method.queue) 现在logs交换将会追加信息到我们的队列。
列出绑定 可以列出当前存在的绑定：
rabbitmqctl list_bindings 最终代码如下
生产者emit_log.py：
#!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, credentials=pika.PlainCredentials(&amp;#39;guest&amp;#39;, &amp;#39;guest&amp;#39;))) channel = connection.channel() channel.</description>
    </item>
    
    <item>
      <title>Rabbitmq Work Queue</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_work_queue/</link>
      <pubDate>Thu, 26 Oct 2017 19:06:17 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_work_queue/</guid>
      <description>&lt;h1 id=&#34;work-queue&#34;&gt;Work Queue&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://www.cheon.site/blog/struct/images/rabbitmq_work_queue_img1.png&#34; alt=&#34;Work Queue 架构图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;工作队列背后的思想是尽量避免立即做资源密集型任务并等待它完成，而是将这些任务放到计划表中，等会儿完成。我们将一个任务封装为一条信息并把它送入一个队列。一个在后台运行的进程将会弹出这些任务并最终执行这个工作。当你运行很多个进程时，任务将会被他们共享。这个概念在web应用中尤为有用，因为在一个简短的HTTP请求中不太可能去处理过于复杂的任务。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rabbitmq Hello World</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_hello_world/</link>
      <pubDate>Thu, 26 Oct 2017 17:17:47 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_hello_world/</guid>
      <description>&lt;h1 id=&#34;hello-world&#34;&gt;Hello World&lt;/h1&gt;

&lt;p&gt;我们将用python写两个简单的程序，一个生产者发送一条信息，一个消费者接受并打印信息。图中的&amp;rdquo;P&amp;rdquo;指代生产者，&amp;rdquo;C&amp;rdquo;指代消费者，中间的盒子指代一个队列——RabbitMQ 的一个消息缓存。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rabbitmq Cluster</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_cluster/</link>
      <pubDate>Thu, 26 Oct 2017 16:28:26 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_cluster/</guid>
      <description>&lt;h1 id=&#34;rabbitmq-docker-运行&#34;&gt;RabbitMQ docker 运行&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -d -p 15672:15672 -p 5672:5672 --hostname rabbit --name rabbit -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;TZ&lt;/span&gt;=Asia/Shanghai -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;RABBITMQ_DEFAULT_USER&lt;/span&gt;=admin -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;RABBITMQ_DEFAULT_PASS&lt;/span&gt;=admin rabbitmq:3-management&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Discourse Digest</title>
      <link>https://www.cheon.site/blog/struct/discourse_digest/</link>
      <pubDate>Tue, 24 Oct 2017 19:27:59 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_digest/</guid>
      <description>&lt;h1 id=&#34;问题说明&#34;&gt;问题说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;discourse 版本：v1.9.0.beta12 +49&lt;/li&gt;
&lt;li&gt;discourse 域名: &lt;a href=&#34;http://test.test.com/community&#34;&gt;http://test.test.com/community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;详细情况：discourse 配置好二级域名后，摘要邮件中取消订阅链接错误&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Discourse Cas</title>
      <link>https://www.cheon.site/blog/struct/discourse_cas/</link>
      <pubDate>Mon, 23 Oct 2017 09:15:44 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_cas/</guid>
      <description>&lt;h1 id=&#34;discourse-cas-登录配置&#34;&gt;discourse cas 登录配置&lt;/h1&gt;

&lt;h2 id=&#34;插件安装&#34;&gt;插件安装&lt;/h2&gt;

&lt;p&gt;cas插件使用&lt;a href=&#34;https://github.com/tyl3k/cas_sso.git&#34;&gt;tyl3k/cas_sso&lt;/a&gt;，在&lt;code&gt;discourse.yml&lt;/code&gt;中添加&lt;code&gt;git clone https://github.com/tyl3k/cas_sso.git&lt;/code&gt;:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Discourse Deploy</title>
      <link>https://www.cheon.site/blog/struct/discourse_deploy/</link>
      <pubDate>Wed, 18 Oct 2017 20:03:58 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_deploy/</guid>
      <description>&lt;h1 id=&#34;discourse-docker-部署&#34;&gt;discourse docker 部署&lt;/h1&gt;

&lt;h2 id=&#34;部署说明&#34;&gt;部署说明&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;目标：以容器的方式部署discourse到网站的二级域名，如 &lt;code&gt;http://test.test.com/community/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;架构：1个postgres数据库，1个redis数据库，1个discourse服务器&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Bash Expansion</title>
      <link>https://www.cheon.site/blog/shell/bash_expansion/</link>
      <pubDate>Fri, 13 Oct 2017 13:43:35 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/shell/bash_expansion/</guid>
      <description>&lt;h1 id=&#34;bash-扩展&#34;&gt;bash 扩展&lt;/h1&gt;</description>
    </item>
    
    <item>
      <title>Bash Tips</title>
      <link>https://www.cheon.site/blog/shell/bash_tips/</link>
      <pubDate>Tue, 10 Oct 2017 11:20:29 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/shell/bash_tips/</guid>
      <description>&lt;h1 id=&#34;bash-代码规范建议&#34;&gt;bash 代码规范建议&lt;/h1&gt;

&lt;p&gt;Bash 可以认为是系统编程级的 JavaScript。虽然在某些时候，使用一门像 C，Go 之类的系统语言是一个更好的选择，但是对于一些小的POSIX相关或命令行任务，Bash 是一门理想的系统语言。这里有几个原因：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bash 无处不在。就像 web 上的 JavaScript，Bash 早就在系统上为系统编程准备好了。&lt;/li&gt;
&lt;li&gt;Bash 可以作为粘合剂。用 C 或 Go （或者其他任意语言）来编写复杂的部分，然后用 Bash 将它们粘合在一起。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>