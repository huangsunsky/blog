<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>log on cheon&#39;s blog</title>
    <link>https://www.cheon.site/blog/tags/log/</link>
    <description>Recent content in log on cheon&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 04 Jul 2019 09:26:33 +0800</lastBuildDate>
    
	<atom:link href="https://www.cheon.site/blog/tags/log/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Logstash to ES</title>
      <link>https://www.cheon.site/blog/struct/logstash_to_es/</link>
      <pubDate>Thu, 04 Jul 2019 09:26:33 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/logstash_to_es/</guid>
      <description>logstash 配置日志发送 ES 日志收集的架构如下所示:
┌────────────┐ │Java logback│\ └────────────┘ \ ┌─────┐ ┌────────┐ ┌──────┐ ┌────────┐ │kafka│ ───&amp;gt; │logstash│ ───&amp;gt; │ ES │ ───&amp;gt; │ kibana │ └─────┘ └────────┘ └──────┘ └────────┘ ┌────────────┐ / │Java logback│/ └────────────┘ java 应用日志通过 logback 发送给 kafka，logstash 从 kafka 消费日志，并将日志转发给 ES。一开始一个应用一个 kafka topic，logstash 消费了之后根据 topic 来确定 ES 的索引。
logback 的配置:
 logback.xml
&amp;lt;appender name=&amp;#34;KAFKA&amp;#34; class=&amp;#34;com.github.danielwegener.logback.kafka.KafkaAppender&amp;#34;&amp;gt; &amp;lt;encoder class=&amp;#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder&amp;#34; charset=&amp;#34;UTF-8&amp;#34; &amp;gt; &amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&amp;lt;/pattern&amp;gt; &amp;lt;/encoder&amp;gt; &amp;lt;topic&amp;gt;spring-boot-demo&amp;lt;/topic&amp;gt; &amp;lt;keyingStrategy class=&amp;#34;com.</description>
    </item>
    
    <item>
      <title>Graylog Sidecar</title>
      <link>https://www.cheon.site/blog/struct/graylog_sidecar/</link>
      <pubDate>Wed, 14 Nov 2018 17:24:04 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_sidecar/</guid>
      <description>graylog sidecar 部署配置 graylog sidecar 用于配置从文件读取日志，具体读取文件可以采用filebeat和nxlog。这里在debian的容器中部署sidecar来示例。
安装sidecar 从下载页面下载对应的包，这里是debian系统，graylog版本是2.4。所以根据文档，下载collector-sidecar_0.1.7-1_amd64.deb：
curl -OL &amp;#34;https://github.com/Graylog2/collector-sidecar/releases/download/0.1.7/collector-sidecar_0.1.7-1_amd64.deb&amp;#34; 下载好后安装：
dpkg -i collector-sidecar_0.1.7-1_amd64.deb 安装好后配置system服务：
graylog-collector-sidecar -service install 这个命令会生成/etc/init.d/collector-sidecar脚步，但是在容器中可能systemctl命令执行不了，可以直接执行该脚本。
配置sidecar 编辑配置文件/etc/graylog/collector-sidecar，改为以下内容：
server_url: http://graylog.test.com/api/ update_interval: 10 tls_skip_verify: false send_status: true list_log_files: - /var/log/connect-check/ collector_id: file:/etc/graylog/collector-sidecar/collector-id cache_path: /var/cache/graylog/collector-sidecar log_path: /var/log/graylog/collector-sidecar log_rotation_time: 86400 log_max_age: 604800 tags: - connect-check backends: - name: nxlog enabled: false binary_path: /usr/bin/nxlog configuration_path: /etc/graylog/collector-sidecar/generated/nxlog.conf - name: filebeat enabled: true binary_path: /usr/bin/filebeat configuration_path: /etc/graylog/collector-sidecar/generated/filebeat.yml 主要是修改server_url和tags两项内容。
生存测试日志 编写一个脚本random.sh来生成一些测试日志：
#!/bin/bash while true; do flag=$RANDOM if [[ $flag -le 10923 ]]; then echo &amp;#34;Accept 200, connect checkout success.</description>
    </item>
    
    <item>
      <title>Graylog K8s Install</title>
      <link>https://www.cheon.site/blog/struct/graylog_k8s_install/</link>
      <pubDate>Wed, 14 Nov 2018 16:20:50 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_k8s_install/</guid>
      <description>graylog k8s 部署 graylog是一个日志聚合工具，用于统一展示应用日志。这里基于官方文档，在k8s集群中部署一套简单的单节点graylog服务。
mongodb 部署 mongodb 在服务中用于存储graylog的配置信息。以下是部署文件（没有进行数据持久化操作）：
 mongodb deploy
# {{{ deploy --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: graylog-mongo labels: app: graylog-mongo spec: replicas: 1 selector: matchLabels: app: graylog-mongo template: metadata: labels: app: graylog-mongo spec: containers: - name: graylog-mongo image: mongo:3 ports: - containerPort: 27017 protocol: TCP resources: limits: memory: 512Mi requests: memory: 100Mi terminationMessagePath: /dev/termination-log imagePullPolicy: IfNotPresent restartPolicy: Always terminationGracePeriodSeconds: 30 dnsPolicy: ClusterFirst securityContext: {} strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 0 maxSurge: 1 revisionHistoryLimit: 2 # }}} # {{{ service --- apiVersion: v1 kind: Service metadata: name: graylog-mongo labels: name: mongo spec: ports: - name: mongo protocol: TCP port: 27017 targetPort: 27017 selector: app: graylog-mongo type: ClusterIP sessionAffinity: None status: loadBalancer: {} # }}}</description>
    </item>
    
    <item>
      <title>Fluentd Config</title>
      <link>https://www.cheon.site/blog/struct/fluentd_config/</link>
      <pubDate>Fri, 05 Jan 2018 10:14:58 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/fluentd_config/</guid>
      <description>命令列表 Fluentd配置文件由以下配置文件组成：
 source命令 指明数据输入源 match命令 指明数据输出源 filter命令 指明事件处理的管道 system命令 指明系统级别配置 label命令 为输出分组并过滤内部路由 include命令 包含其他文件  命令详解  source: 数据的来源
Fluentd的输入源通过source命令选择和配置想要的输入插件来启用。Fluentd的标准输入插件包括http和forward。http使得Fluentd转变为一个HTTP终端用于接收到来的HTTP信息，而forward将fluentd转变为一个TCP终端用于接收TCP包。当然，它们可以被同时启用。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.host:9880/myapp.access?json={&amp;#34;event&amp;#34;:&amp;#34;data&amp;#34;} &amp;lt;source&amp;gt; @type http port 9880 &amp;lt;/source&amp;gt; 每一个source命令必须包含一个type参数。type参数指定使用哪一个输入插件。
 match: 告诉fluentd做什么
match命令寻找匹配标签的事件并且处理它们。match命令最常见的用法是将事件输出到其他系统（由于这个原因，这些插件被称为”输出插件“）。Fluentd的标准输出插件包括file和forward。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.</description>
    </item>
    
  </channel>
</rss>