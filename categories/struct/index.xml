<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>struct on cheon&#39;s blog</title>
    <link>https://www.cheon.site/blog/categories/struct/</link>
    <description>Recent content in struct on cheon&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 01 Aug 2019 16:34:31 +0800</lastBuildDate>
    
	<atom:link href="https://www.cheon.site/blog/categories/struct/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>K8s Note</title>
      <link>https://www.cheon.site/blog/struct/k8s_note/</link>
      <pubDate>Thu, 01 Aug 2019 16:34:31 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/k8s_note/</guid>
      <description>k8s 备忘 ingress 配置证书 首先要在 ingress 所在 namespace 下创建 tls 类型的 secret:
kubectl create secret tls https-certs --key /path/to/keyfile --cert /path/to/certfile -n the-namespace 修改 ingress 配置，kubectl edit ing ingname -n the-namespace，在 spec 添加如下内容，注意和 rules 同级:
tls: - hosts: - www.test.com secretName: https-certs ingress 配置了 https 证书后默认会强制跳转到 https 协议，如果不想强制跳转，可以在 annotations 添加如下配置:
nginx.ingress.kubernetes.io/ssl-redirect: &amp;#34;false&amp;#34; 旧版本的配置无需加上 nginx 前缀:
ingress.kubernetes.io/ssl-redirect: &amp;#34;false&amp;#34; 更多的 annotations 配置可以查看 github 文档
ingress 配置超时 应用接口响应较慢的情况下可能需要修改 nginx 的超时配置，默认是 60s，可以在 annotations 添加如下配置:</description>
    </item>
    
    <item>
      <title>Logstash to ES</title>
      <link>https://www.cheon.site/blog/struct/logstash_to_es/</link>
      <pubDate>Thu, 04 Jul 2019 09:26:33 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/logstash_to_es/</guid>
      <description>logstash 配置日志发送 ES 日志收集的架构如下所示:
┌────────────┐ │Java logback│\ └────────────┘ \ ┌─────┐ ┌────────┐ ┌──────┐ ┌────────┐ │kafka│ ───&amp;gt; │logstash│ ───&amp;gt; │ ES │ ───&amp;gt; │ kibana │ └─────┘ └────────┘ └──────┘ └────────┘ ┌────────────┐ / │Java logback│/ └────────────┘ java 应用日志通过 logback 发送给 kafka，logstash 从 kafka 消费日志，并将日志转发给 ES。一开始一个应用一个 kafka topic，logstash 消费了之后根据 topic 来确定 ES 的索引。
logback 的配置:
 logback.xml
&amp;lt;appender name=&amp;#34;KAFKA&amp;#34; class=&amp;#34;com.github.danielwegener.logback.kafka.KafkaAppender&amp;#34;&amp;gt; &amp;lt;encoder class=&amp;#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder&amp;#34; charset=&amp;#34;UTF-8&amp;#34; &amp;gt; &amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&amp;lt;/pattern&amp;gt; &amp;lt;/encoder&amp;gt; &amp;lt;topic&amp;gt;spring-boot-demo&amp;lt;/topic&amp;gt; &amp;lt;keyingStrategy class=&amp;#34;com.</description>
    </item>
    
    <item>
      <title>Ceph Ansible</title>
      <link>https://www.cheon.site/blog/struct/ceph_ansible/</link>
      <pubDate>Sun, 23 Jun 2019 16:45:52 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/ceph_ansible/</guid>
      <description>Ceph 介绍 无论是想要为云平台提供 Ceph Object Storage 或 Ceph Block Device 服务，部署一个 Ceph Filesystem 总是从设置每一个 Ceph 节点，网络和 Ceph 存储集群开始。一个 Ceph 存储集群至少需要一个 Ceph Monitor，Ceph Manger，和 Ceph OSD(Object Storage Daemon)。当运行 Ceph 文件系统客户端时也需要 Ceph Metadata Server。
 Monitors: 一个 Ceph 监视器(ceph-mon) 维护集群状态的映射，包括监视器，管理，OSD 和 CURSH 映射。这些映射是 Ceph 守护进程之间相互协调的关键。监视器还负责管理守护进程和客户端之间的身份验证。为了保证冗余和高可用，至少需要3个监视器。
 Mangers: 一个 Ceph 管理(ceph-mgr)守护进程负责保持追踪 Ceph 集群运行时指标和当前集群状态，包括存储利用率，当前的性能指标和系统负载。Ceph 管理进程还托管基于 python 的模块来管理和公开 Ceph 集群信息，包括一个基于网页的 Ceph Dashboard 和 REST API。为了保证高可用，至少需要2个管理节点。
 Ceph OSDs: 一个 Ceph OSD(object storage daemon, ceph-osd)存储数据，处理数据复制、恢复、重新平衡，并通过检查其他 Ceph OSD 进程的心跳来提供一些监控信息给 Ceph 监视器和管理。为了保证冗余和高可用，至少需要3个 Ceph OSDs。</description>
    </item>
    
    <item>
      <title>Docker Graph Migrate</title>
      <link>https://www.cheon.site/blog/struct/docker_graph_migrate/</link>
      <pubDate>Tue, 14 May 2019 19:33:12 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/docker_graph_migrate/</guid>
      <description>docker 目录迁移 服务器根目录磁盘空间比较小，只有50G，在使用一段时间后镜像增多，磁盘不够用，准备将 docker 的目录挂载到新加的磁盘。挂载硬盘后如下：
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 3.7M 0 rom vda 253:0 0 50G 0 disk └─vda1 253:1 0 50G 0 part / vdb 253:16 0 200G 0 disk 创建 lvm 为了以后方便扩容，准备使用 lvm。首先创建 pv：
pvcreate /dev/vdb 创建 vg，命名为 docker：
vgcreate docker /dev/vdb 创建 lv，命名为 registry：
lvcreate -l +100%Free docker --name registry 将 lv 格式化为 xfs 文件系统：
mkfs.xfs /dev/docker/registry 替换目录 首先要将改节点的 pod 全都驱散走：</description>
    </item>
    
    <item>
      <title>Skywalking Deploy</title>
      <link>https://www.cheon.site/blog/struct/skywalking_deploy/</link>
      <pubDate>Thu, 25 Apr 2019 17:16:15 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/skywalking_deploy/</guid>
      <description>skywalking 部署 skywalking 是一个国产开源的调用链监控工具，可用于分析请求中哪些操作比较慢。官方提供了 k8s 的部署配置，但这个配置里的镜像是不对的，具体版本对应的镜像可以在Dockerhub上找到。如果想要更换版本，最好把 ES 中的索引先删除，否则可能会导致应用报错。
架构说明  elasticsearch: 用于存储 skywalking 数据，这里使用的是腾讯云的 ES 服务，因此无需搭建 skywalking-oap-server: skywalking 后端 ui: 默认 ui 界面 rocketbot-ui: skywalking 的另一个官方前端界面，没有现成的镜像，需要自己构建  部署 将官方的部署文件克隆到本地，将 oap， ui 的镜像换成对应的版本镜像。修改 oap 配置中的 ES 地址：
storage: elasticsearch: clusterNodes: elasticsearch:9200 先创建命名空间：
kubectl create ns skywalking 接着部署 oap 后端：
kubectl apply -f oap/ 再部署前端：
kubectl apply -f ui/ 为了集群外部访问，可以为前端配置一个域名或者在 service 中添加 externalIPs。
apiVersion: extensions/v1beta1 kind: Ingress metadata: generation: 1 name: ui namespace: skywalking spec: rules: - host: skywalking.</description>
    </item>
    
    <item>
      <title>Graylog Sidecar</title>
      <link>https://www.cheon.site/blog/struct/graylog_sidecar/</link>
      <pubDate>Wed, 14 Nov 2018 17:24:04 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_sidecar/</guid>
      <description>graylog sidecar 部署配置 graylog sidecar 用于配置从文件读取日志，具体读取文件可以采用filebeat和nxlog。这里在debian的容器中部署sidecar来示例。
安装sidecar 从下载页面下载对应的包，这里是debian系统，graylog版本是2.4。所以根据文档，下载collector-sidecar_0.1.7-1_amd64.deb：
curl -OL &amp;#34;https://github.com/Graylog2/collector-sidecar/releases/download/0.1.7/collector-sidecar_0.1.7-1_amd64.deb&amp;#34; 下载好后安装：
dpkg -i collector-sidecar_0.1.7-1_amd64.deb 安装好后配置system服务：
graylog-collector-sidecar -service install 这个命令会生成/etc/init.d/collector-sidecar脚步，但是在容器中可能systemctl命令执行不了，可以直接执行该脚本。
配置sidecar 编辑配置文件/etc/graylog/collector-sidecar，改为以下内容：
server_url: http://graylog.test.com/api/ update_interval: 10 tls_skip_verify: false send_status: true list_log_files: - /var/log/connect-check/ collector_id: file:/etc/graylog/collector-sidecar/collector-id cache_path: /var/cache/graylog/collector-sidecar log_path: /var/log/graylog/collector-sidecar log_rotation_time: 86400 log_max_age: 604800 tags: - connect-check backends: - name: nxlog enabled: false binary_path: /usr/bin/nxlog configuration_path: /etc/graylog/collector-sidecar/generated/nxlog.conf - name: filebeat enabled: true binary_path: /usr/bin/filebeat configuration_path: /etc/graylog/collector-sidecar/generated/filebeat.yml 主要是修改server_url和tags两项内容。
生存测试日志 编写一个脚本random.sh来生成一些测试日志：
#!/bin/bash while true; do flag=$RANDOM if [[ $flag -le 10923 ]]; then echo &amp;#34;Accept 200, connect checkout success.</description>
    </item>
    
    <item>
      <title>Graylog K8s Install</title>
      <link>https://www.cheon.site/blog/struct/graylog_k8s_install/</link>
      <pubDate>Wed, 14 Nov 2018 16:20:50 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/graylog_k8s_install/</guid>
      <description>graylog k8s 部署 graylog是一个日志聚合工具，用于统一展示应用日志。这里基于官方文档，在k8s集群中部署一套简单的单节点graylog服务。
mongodb 部署 mongodb 在服务中用于存储graylog的配置信息。以下是部署文件（没有进行数据持久化操作）：
 mongodb deploy
# {{{ deploy --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: graylog-mongo labels: app: graylog-mongo spec: replicas: 1 selector: matchLabels: app: graylog-mongo template: metadata: labels: app: graylog-mongo spec: containers: - name: graylog-mongo image: mongo:3 ports: - containerPort: 27017 protocol: TCP resources: limits: memory: 512Mi requests: memory: 100Mi terminationMessagePath: /dev/termination-log imagePullPolicy: IfNotPresent restartPolicy: Always terminationGracePeriodSeconds: 30 dnsPolicy: ClusterFirst securityContext: {} strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 0 maxSurge: 1 revisionHistoryLimit: 2 # }}} # {{{ service --- apiVersion: v1 kind: Service metadata: name: graylog-mongo labels: name: mongo spec: ports: - name: mongo protocol: TCP port: 27017 targetPort: 27017 selector: app: graylog-mongo type: ClusterIP sessionAffinity: None status: loadBalancer: {} # }}}</description>
    </item>
    
    <item>
      <title>Ansible Variables</title>
      <link>https://www.cheon.site/blog/struct/ansible_variables/</link>
      <pubDate>Fri, 25 May 2018 11:06:47 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/ansible_variables/</guid>
      <description>ansible 变量 ansible 变量以[A-Za-z]开头，可以包含下划线_和数字[0-9]，标准是全部使用小写字母。在清单(inventory)文件里，变量使用=赋值，如：
foo=bar 在剧本(playbook)或变量文件里，变量用:赋值，如：
foo: bar Playbook Variables 变量可以在使用ansible-playbook时通过命令行参数--extra-vars选项传递：
ansible-playbook example.yml --extra-vars &amp;#34;foo=bar&amp;#34; 也可以在参数中传递json，yaml格式的数据，甚至是json和yaml文件，就像--extra-vars &amp;quot;@even_more_vars.json&amp;quot;或者--extra-vars &amp;quot;@even_more_vars.yml&amp;quot;，但这种方式不建议使用。
变量可以直接在playbook中的vars部分定义：
--- - hosts: example vars: foo: bar tasks: # Prints &amp;#34;Variable &amp;#39;foo&amp;#39; is set to bar&amp;#34;. - debug: msg=&amp;#34;Variable &amp;#39;foo&amp;#39; is set to {{ foo }}&amp;#34; 变量也可以在单独的文件中定义，然后在playbook中通过vars_files引用：
# Main playbook file. - hosts: example vars_files: - vars.yml tasks: - debug: msg=&amp;#34;Variable &amp;#39;foo&amp;#39; is set to {{ foo }}&amp;#34; 和playbook同目录下的vars.yml：
# Variables file &amp;#39;vars.</description>
    </item>
    
    <item>
      <title>Glusterfs Deploy</title>
      <link>https://www.cheon.site/blog/struct/glusterfs_deploy/</link>
      <pubDate>Tue, 09 Jan 2018 10:09:35 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/glusterfs_deploy/</guid>
      <description>glusterfs centos 部署 GlusterFS是一个开源的分布式文件系统，这里部署它主要为了解决文件存储的单点问题。
虚拟机配置 此处采用vagrant部署centos的虚拟机三台，box可以采用bento/centos7.2，配置文件如下：
Vagrant.configure(&amp;#34;2&amp;#34;) do |config| (1..3).each do |i| config.vm.define &amp;#34;gluster-node#{i}&amp;#34; do |node| file_to_disk = &amp;#34;tmp/gluster_node#{i}_disk.vdi&amp;#34; node.vm.box = &amp;#34;centos-7.2&amp;#34; node.vm.hostname = &amp;#34;gluster-node#{i}&amp;#34; n = 100 +i node.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.12.#{n}&amp;#34; node.vm.provider &amp;#34;virtualbox&amp;#34; do |vb| unless File.exist?(file_to_disk) vb.customize [&amp;#39;createhd&amp;#39;, &amp;#39;--filename&amp;#39;, file_to_disk, &amp;#39;--size&amp;#39;, 10 * 1024] vb.customize [&amp;#39;storageattach&amp;#39;, :id, &amp;#39;--storagectl&amp;#39;, &amp;#39;SATA Controller&amp;#39;, &amp;#39;--port&amp;#39;, 1, &amp;#39;--device&amp;#39;, 0, &amp;#39;--type&amp;#39;, &amp;#39;hdd&amp;#39;, &amp;#39;--medium&amp;#39;, file_to_disk] end vb.name = &amp;#34;gluster-node#{i}&amp;#34; vb.cpus = 1 vb.memory = 1024 end end end end 该配置文件根据官方quick start文档，为虚拟机配置了第二磁盘，用于GlusterFS存储，大小为10G。</description>
    </item>
    
    <item>
      <title>Fluentd Config</title>
      <link>https://www.cheon.site/blog/struct/fluentd_config/</link>
      <pubDate>Fri, 05 Jan 2018 10:14:58 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/fluentd_config/</guid>
      <description>命令列表 Fluentd配置文件由以下配置文件组成：
 source命令 指明数据输入源 match命令 指明数据输出源 filter命令 指明事件处理的管道 system命令 指明系统级别配置 label命令 为输出分组并过滤内部路由 include命令 包含其他文件  命令详解  source: 数据的来源
Fluentd的输入源通过source命令选择和配置想要的输入插件来启用。Fluentd的标准输入插件包括http和forward。http使得Fluentd转变为一个HTTP终端用于接收到来的HTTP信息，而forward将fluentd转变为一个TCP终端用于接收TCP包。当然，它们可以被同时启用。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.host:9880/myapp.access?json={&amp;#34;event&amp;#34;:&amp;#34;data&amp;#34;} &amp;lt;source&amp;gt; @type http port 9880 &amp;lt;/source&amp;gt; 每一个source命令必须包含一个type参数。type参数指定使用哪一个输入插件。
 match: 告诉fluentd做什么
match命令寻找匹配标签的事件并且处理它们。match命令最常见的用法是将事件输出到其他系统（由于这个原因，这些插件被称为”输出插件“）。Fluentd的标准输出插件包括file和forward。
# Receive events from 24224/tcp # This is used by log forwarding and the fluent-cat command &amp;lt;source&amp;gt; @type forward port 24224 &amp;lt;/source&amp;gt; # http://this.</description>
    </item>
    
    <item>
      <title>K8s Cluster Deploy</title>
      <link>https://www.cheon.site/blog/struct/k8s_cluster_deploy/</link>
      <pubDate>Mon, 04 Dec 2017 09:19:26 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/k8s_cluster_deploy/</guid>
      <description>vagrant kubernetes 集群部署 集群说明 集群共有四个节点，一个master节点，四个子节点，其中一个节点即是master节点，也是node节点，系统均为centos-7.2。
k8s-node1 192.168.12.81 master, node k8s-node2 192.168.12.82 node k8s-node3 192.168.12.83 node k8s-node4 192.168.12.84 node vagrant 配置 vagrant 的 box 可选用 bento/centos-7.2:
 Vagrantfile
# -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The &amp;#34;2&amp;#34; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don&amp;#39;t change it unless you know what # you&amp;#39;re doing.</description>
    </item>
    
    <item>
      <title>Maven &amp; Nexus</title>
      <link>https://www.cheon.site/blog/struct/maven_nexus/</link>
      <pubDate>Thu, 09 Nov 2017 10:47:30 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/maven_nexus/</guid>
      <description>maven 配置使用 nexus 私服 修改~/.m2/settings.xml内容如下：
 mvn config
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;settings xmlns=&amp;#34;http://maven.apache.org/SETTINGS/1.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&amp;#34;&amp;gt; &amp;lt;servers&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;releases&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;thirdpart&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;admin&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;admin123&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;/servers&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;central&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;central&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public/&amp;lt;/url&amp;gt; &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; &amp;lt;/settings&amp;gt; 
在项目的 pom.xml 文件中添加如下内容：
 pom config
&amp;lt;distributionManagement&amp;gt; &amp;lt;snapshotRepository&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Snapshot Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/snapshots/&amp;lt;/url&amp;gt; &amp;lt;/snapshotRepository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;releases&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Release Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/releases/&amp;lt;/url&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;/distributionManagement&amp;gt; &amp;lt;repositories&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;public&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Public&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Snapshots&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/snapshots&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;repository&amp;gt; &amp;lt;id&amp;gt;thirdparty&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;3rd party&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/repositories/thirdparty/&amp;lt;/url&amp;gt; &amp;lt;releases&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/releases&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/repository&amp;gt; &amp;lt;/repositories&amp;gt; &amp;lt;pluginRepositories&amp;gt; &amp;lt;pluginRepository&amp;gt; &amp;lt;id&amp;gt;public&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;Plugin Repository&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8081/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;layout&amp;gt;default&amp;lt;/layout&amp;gt; &amp;lt;snapshots&amp;gt; &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt; &amp;lt;/snapshots&amp;gt; &amp;lt;/pluginRepository&amp;gt; &amp;lt;/pluginRepositories&amp;gt;</description>
    </item>
    
    <item>
      <title>Etcd &amp; Flannel</title>
      <link>https://www.cheon.site/blog/struct/etcd_and_flannel/</link>
      <pubDate>Wed, 01 Nov 2017 17:58:29 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/etcd_and_flannel/</guid>
      <description>etcd &amp;amp; flannel 实现跨主机容器通信 准备工作  测试环境：vagrant + centos7.2 虚拟机 主机说明：  ip: 192.168.12.101 hostname: node1 安装软件：etcd, flannel, docker ip: 192.168.12.102 hostname: node2 安装软件：flannel, docker   启动虚拟机 vagrant配置文件：
 Vagrantfile
# -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(2) do |config| (1..2).each do |i| config.vm.define &amp;#34;node#{i}&amp;#34; do |s| s.vm.box = &amp;#34;bento/centos-7.2&amp;#34; s.vm.hostname = &amp;#34;node#{i}&amp;#34; n = 100 + i s.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.12.#{n}&amp;#34; s.ssh.username = &amp;#34;vagrant&amp;#34; s.</description>
    </item>
    
    <item>
      <title>Rabbitmq Access Control</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_access_control/</link>
      <pubDate>Mon, 30 Oct 2017 09:48:14 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_access_control/</guid>
      <description>Rabbitmq 权限控制 在rabbitmq中，身份验证和授权是分开的。身份验证用于判断用户是谁，授权用于确定用户能做什么和不能做什么。
默认虚拟主机和用户 当服务第一次启动或者检测到数据库梅雨初始化或已经被删除，rabbitmq会初始化一个新的数据库，拥有如下资源：
 一个虚拟主机/ 一个用户名和密码都为guest的用户，拥有/虚拟主机的所有权限  建议是删除默认用户或者修改默认用户的密码。guest用户默认情况只能通过localhost连接，无法通过远程连接。这可以通过配置文件修改，设置loopback_users.guest = false即可。
权限工作方式 rabbitmq的权限控制主要分为两层，第一层是虚拟主机的权限，第二层是资源的权限。
虚拟主机(Virtual Host) 当客户端连接到服务器，它会指定一个要操作的虚拟主机，第一层权限控制被启用，服务器会检查用户对该虚拟主机是否有权限，没有权限连接会被拒绝。
示例：
首先创建一个用户：
rabbitmqctl add_user cheon 123 这里创建了一个用户cheon，密码为123（如果rabbitmq是集群，那么在集群中一个节点上创建了用户，虚拟主机等，在其他节点上也都会存在。）。刚创建的用户是没有任何权限的。可以确认一下用户的权限：
root@rabbitmq-node1:/# rabbitmqctl list_user_permissions cheon Listing permissions for user &amp;#34;cheon&amp;#34; ... root@rabbitmq-node1:/# rabbitmqctl list_user_permissions guest Listing permissions for user &amp;#34;guest&amp;#34; ... /	.*	.*	.* 可以看到新用户cheon没有任何权限，guest用户拥有虚拟主机/的全部权限。
编写一个简单的脚本，通过用户cheon连接/虚拟主机，发送Hello World：
#!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, &amp;#34;/&amp;#34;, credentials=pika.PlainCredentials(&amp;#39;cheon&amp;#39;, &amp;#39;123&amp;#39;))) channel = connection.channel() channel.queue_declare(queue=&amp;#39;hello&amp;#39;) channel.basic_publish( exchange=&amp;#39;&amp;#39;, routing_key=&amp;#39;hello&amp;#39;, body=&amp;#39;Hello World!</description>
    </item>
    
    <item>
      <title>Rabbitmq Topic</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_topic/</link>
      <pubDate>Sun, 29 Oct 2017 20:32:52 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_topic/</guid>
      <description>rabbitmq 主题 虽然之前使用了direct交换来路由不同级别的日志，但是它无法做到根据设备来路由。在我们的日志系统中，可能不止是想要通过日志级别来订阅，还想通过日志来源订阅。这将会给我们带来更大的灵活性，比如我们可以只监听来自cron的error和来自kern的所有日志。为了达到这个效果，我们可以采用一个更复杂的交换&amp;ndash;topic。
Topic exchange 发送给topic交换的信息的routing_key的属性不能是任意的&amp;ndash;它必须是一个单词的列表，通过.分隔。单词可以是任意的，但是通常是一些描述信息特征的词语。例如stock.usd.nyse，nyse.vmw，quick.orange.rabbit。你可以设置任意多的词语，只要不超过255字节的限制。
binding key也必须是相同的格式。topic背后的交换逻辑和direct是相似的，一个带有特殊routing key的信息会被发送到所有拥有匹配binding key的队列，但有两个需要注意的地方：
 * 可以代表一个单词 # 可以代表0或多个单词  示例：
在这个示例中，我们发送描述动物的消息。消息会带有由三个单词组成的routing key，单词间用.分隔，用于描述不同的特征。我们创建了三个绑定：Q1和*.orange.*绑定，Q2和*.*.rabbit，lazy.#绑定。可以简单得概括为Q1只关心所有橙色的动物，Q2只关心兔子和慢吞吞的动物。
一条带有quick.orange.rabbit的routing key的信息会发送给两个队列，quick.orange.fox也会发送给两个，lazy.brown.fox只发送给Q2，lazy.pink.rabbit只发送给Q2一次，即使它匹配了两个绑定。quick.brown.fox不匹配任何绑定所以会被丢弃。如果我们发送的信息带有一个或四个单词，像orange，quick.orange.male.rabbit之类的，也不匹配任何绑定，也会被丢弃 。但是lazy.orange.male.rabbit虽然有四个单词，也匹配lazy.#，因为#代表0或多个单词，所以会被发送给Q2。
topic是一个强大的交换，可以实现其他交换的功能。当一个队列绑定#，它可以接收所有信息，就像fanout交换。当没有使用*和#，而是指定明确的字符串，就可以表现地像direct交换。
最终实现 我们假设日志的routing key有两个单词&amp;lt;facility&amp;gt;.&amp;lt;severity&amp;gt;，那么代码如下：
emit_log_topic.py：
#!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, credentials=pika.PlainCredentials(&amp;#39;guest&amp;#39;, &amp;#39;guest&amp;#39;))) channel = connection.channel() channel.exchange_declare( exchange=&amp;#39;topic_logs&amp;#39;, exchange_type=&amp;#39;topic&amp;#39; ) severity = sys.argv[1] if len(sys.argv) &amp;gt; 2 else &amp;#39;info&amp;#39; message = &amp;#39; &amp;#39;.join(sys.argv[2:]) or &amp;#39;Hello World!&amp;#39; channel.basic_publish( exchange=&amp;#39;topic_logs&amp;#39;, routing_key=severity, body=message ) print(&amp;#34; [x] Sent %r:%r&amp;#34; % (severity, message)) connection.</description>
    </item>
    
    <item>
      <title>Rabbitmq Routing</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_routing/</link>
      <pubDate>Sat, 28 Oct 2017 09:26:49 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_routing/</guid>
      <description>Rabbitmq 路由 这里我们将为日志系统增加一个特性&amp;ndash;只订阅一部分信息。例如，我们可以将错误信息存入日志文件，将其他信息打印出来。
绑定（Bindings） 在日志系统中我们已经使用过绑定，像这样调用代码：
channel.queue_bind( exchange=exchange_name, queue=queue_name ) 一个绑定是交换和队列之间的关系，可以简单地理解为这个队列只对这个交换的信息感兴趣。绑定可以指定额外的routing_key参数。为了避免和一个basic_publish参数混淆，我们称它binding key，可以通过一下方式创建一个带有key的绑定：
channel.queue_bind( exchange=exchange_name, queue=queue_name, routing_key=&amp;#39;black&amp;#39; ) binding key的含义依赖于交换的类型。fanout交换类型会直接忽略这个值。
Direct exchange 我们之前的日志系统使用fanout交换类型，直接将信息广播给所有消费者。现在我们想要扩展它允许根据根据级别来过滤。例如，将错误级别的日志存入磁盘，将普通的日志直接输出而不浪费磁盘空间。为了达到这个目的，这里将使用direct交换。direct交换的路由算法也比较简单，一个消息只推送到binding key和routing key匹配的队列，举例如下图：
在上述例子中可以看到direct交换x有两个与之绑定的队列。第一个队列的binding key是orange，第二个队列有两个binding key，分别是black和green。通过这个配置，一个带有orage的routing key的信息推送到交换后会被路由到队列Q1；一个带有black或者green的routing key的信息推送到交换后会被路由到队列Q2，其他的信息会被丢弃。
多绑定（Muliple bindings） 用相同的binding key绑定多个队列完全是可行的。在我们的例子中可以在x和Q1之间添加一个名为black的binding key，这样的话，direct交换将会表现得像fanout并且会将信息广播到所有匹配的队列。一个带有black的routing key的信息会递送到Q1和Q2队列。
发送日志 我们将使用这个模型来构建日志系统，我们将会发送信息到direct交换，我们将会以日志的级别作为routing key。首先创建交换：
channel.exchange_declare( exchange=&amp;#39;direct_logs&amp;#39;, exchange_type=&amp;#39;direct&amp;#39; ) 然后发送消息：
channel.basic_publish( exchange=&amp;#39;direct_logs&amp;#39;, routing_key=serverity, body=message ) 为了简化程序，我们假设日志级别只有info，warning，error三种情况。
订阅 我们将为每一个需要的日志级别创建一个新的绑定：
result = channel.queue_declare(exclusive=True) queue_name = result.method.queue for severity in severities: channel.queue_bind( exchange=&amp;#39;direct_logs&amp;#39;, queue=queue_name, routing_key=severity ) 最终结果 emit_log_direct.py：
#!/usr/bin/env python import pika import sys connection = pika.</description>
    </item>
    
    <item>
      <title>Rabbitmq Publish Subscribe</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_publish_subscribe/</link>
      <pubDate>Fri, 27 Oct 2017 15:18:38 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_publish_subscribe/</guid>
      <description>Publish Subcribe 发布和订阅模式简单而言就是将一个消息发送个多个消费者。为了阐明这个模式，这里将会构建一个简单的日志系统，这个系统由两部分组成，第一个程序发送消息，第二个程序接收和打印消息。
在该日志系统中，接收程序的每一个运行副本都将得到消息，这样我们可以运行一个接收器，并将日志存放在磁盘；同时运行另一个接收器将日志在屏幕上打印出来。
交换(Exchanges) rabbitmq 消息模型的核心是生产者从不直接发送任何消息到队列。事实上，一个生产者经常不知道一个消息是否被发送到了队列。生产者只能将消息发送给交换。交换是一个非常简单的东西，它一边接收来自生产者的消息，另一边它把消息推入消息队列。交换是一定知道要怎么处理它接收到的消息的。应该被追加到一个特定的队列后，还是应该追加到多个队列中，还是应该被丢弃。这些规则都由交换类型（exchange type）定义。
有一些可用的交换类型：direct, topic, headers 和 fanout，这里将使用最后一个类型&amp;ndash;fanout。创建一个名为logs的该类型交换：
channel.exchange_declare(exchange=&amp;#39;logs&amp;#39;, exchange_type=&amp;#39;fanout&amp;#39;) fanout类型的交换非常简单。就如它的名字一样，它只是将它接收到的信息广播到它知道的所有队列，这正是我们日志系统所需要的。
查看交换 列出服务器上可用的交换可以使用rabbitmqctl命令:
rabbitmqctl list_exchanges 在列表中会有一些amq.*的交换和默认（未命名）的交换。这些是默认配置的，但是这里目前用不到他们。
有时候我们通过空字符串&#39;&#39;来使用默认的交换：
channel.basic_publish(exchange=&amp;#39;&amp;#39;, routing_key=&amp;#39;hello&amp;#39;, body=message) 现在我们可以推送到我们的命名交换中：
channel.basic_publish( exchange=&amp;#39;logs&amp;#39; routing_key=&amp;#39;&amp;#39;, body=message ) 临时队列 有时我们使用的队列有指定的名字，能够为队列命名是至关重要的，我们需要指定工作到相同的队列。当你想要在生产者和消费者间共享队列时为队列命名是很重要的。但是在我们的日志系统中，我们想要监听所有的日志，而不是一些；我们也只对当前流动的信息感兴趣而不是旧的信息。要达到这个效果我们需要两件事。
第一，无论何时连接到rabbitmq我们需要刷新，清空队列。为了做到这个我们可以用随机名字创建一个队列，或者更好的是让服务器为我们选择一个随机的队列名字。可以通过不给queue参数到queue_declare来做到这一点：
result = channel.queue_declare() 这个时候result.method.queue包含了一个随机的队列名。例如它可能看起来像amq.gen-JzTY20BRgKO-HjmUJj0wLg
第二，一旦消费者连接被关闭，队列应该被删除，有一个exclusive标签：
result = channel.queue_declare(excusive=True) 可以在队列指南获取更多exclusive标签和其他队列属性。
绑定（Bindings） 我们已经创建了一个fanout类型的交换。现在我们需要告诉交换发送信息给我们的队列。交换和队列之间的关系叫做绑定：
channel.queue_bind(exchange=&amp;#39;logs&amp;#39;, queue=result.method.queue) 现在logs交换将会追加信息到我们的队列。
列出绑定 可以列出当前存在的绑定：
rabbitmqctl list_bindings 最终代码如下
生产者emit_log.py：
#!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(&amp;#39;172.17.0.6&amp;#39;, 5672, credentials=pika.PlainCredentials(&amp;#39;guest&amp;#39;, &amp;#39;guest&amp;#39;))) channel = connection.channel() channel.</description>
    </item>
    
    <item>
      <title>Rabbitmq Work Queue</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_work_queue/</link>
      <pubDate>Thu, 26 Oct 2017 19:06:17 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_work_queue/</guid>
      <description>&lt;h1 id=&#34;work-queue&#34;&gt;Work Queue&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://www.cheon.site/blog/struct/images/rabbitmq_work_queue_img1.png&#34; alt=&#34;Work Queue 架构图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;工作队列背后的思想是尽量避免立即做资源密集型任务并等待它完成，而是将这些任务放到计划表中，等会儿完成。我们将一个任务封装为一条信息并把它送入一个队列。一个在后台运行的进程将会弹出这些任务并最终执行这个工作。当你运行很多个进程时，任务将会被他们共享。这个概念在web应用中尤为有用，因为在一个简短的HTTP请求中不太可能去处理过于复杂的任务。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rabbitmq Hello World</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_hello_world/</link>
      <pubDate>Thu, 26 Oct 2017 17:17:47 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_hello_world/</guid>
      <description>&lt;h1 id=&#34;hello-world&#34;&gt;Hello World&lt;/h1&gt;

&lt;p&gt;我们将用python写两个简单的程序，一个生产者发送一条信息，一个消费者接受并打印信息。图中的&amp;rdquo;P&amp;rdquo;指代生产者，&amp;rdquo;C&amp;rdquo;指代消费者，中间的盒子指代一个队列——RabbitMQ 的一个消息缓存。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rabbitmq Cluster</title>
      <link>https://www.cheon.site/blog/struct/rabbitmq_cluster/</link>
      <pubDate>Thu, 26 Oct 2017 16:28:26 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/rabbitmq_cluster/</guid>
      <description>&lt;h1 id=&#34;rabbitmq-docker-运行&#34;&gt;RabbitMQ docker 运行&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -d -p 15672:15672 -p 5672:5672 --hostname rabbit --name rabbit -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;TZ&lt;/span&gt;=Asia/Shanghai -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;RABBITMQ_DEFAULT_USER&lt;/span&gt;=admin -e &lt;span style=&#34;color:#666;font-weight:bold;font-style:italic&#34;&gt;RABBITMQ_DEFAULT_PASS&lt;/span&gt;=admin rabbitmq:3-management&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Discourse Digest</title>
      <link>https://www.cheon.site/blog/struct/discourse_digest/</link>
      <pubDate>Tue, 24 Oct 2017 19:27:59 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_digest/</guid>
      <description>&lt;h1 id=&#34;问题说明&#34;&gt;问题说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;discourse 版本：v1.9.0.beta12 +49&lt;/li&gt;
&lt;li&gt;discourse 域名: &lt;a href=&#34;http://test.test.com/community&#34;&gt;http://test.test.com/community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;详细情况：discourse 配置好二级域名后，摘要邮件中取消订阅链接错误&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Discourse Cas</title>
      <link>https://www.cheon.site/blog/struct/discourse_cas/</link>
      <pubDate>Mon, 23 Oct 2017 09:15:44 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_cas/</guid>
      <description>&lt;h1 id=&#34;discourse-cas-登录配置&#34;&gt;discourse cas 登录配置&lt;/h1&gt;

&lt;h2 id=&#34;插件安装&#34;&gt;插件安装&lt;/h2&gt;

&lt;p&gt;cas插件使用&lt;a href=&#34;https://github.com/tyl3k/cas_sso.git&#34;&gt;tyl3k/cas_sso&lt;/a&gt;，在&lt;code&gt;discourse.yml&lt;/code&gt;中添加&lt;code&gt;git clone https://github.com/tyl3k/cas_sso.git&lt;/code&gt;:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Discourse Deploy</title>
      <link>https://www.cheon.site/blog/struct/discourse_deploy/</link>
      <pubDate>Wed, 18 Oct 2017 20:03:58 +0800</pubDate>
      
      <guid>https://www.cheon.site/blog/struct/discourse_deploy/</guid>
      <description>&lt;h1 id=&#34;discourse-docker-部署&#34;&gt;discourse docker 部署&lt;/h1&gt;

&lt;h2 id=&#34;部署说明&#34;&gt;部署说明&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;目标：以容器的方式部署discourse到网站的二级域名，如 &lt;code&gt;http://test.test.com/community/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;架构：1个postgres数据库，1个redis数据库，1个discourse服务器&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>